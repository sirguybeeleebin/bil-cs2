{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d721c98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56493/56493 [00:16<00:00, 3460.62it/s]\n",
      "100%|██████████| 37974/37974 [00:07<00:00, 5050.83it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 4871.94it/s]\n",
      "100%|██████████| 37974/37974 [00:00<00:00, 38703.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итерация отбора признаков: 1\n",
      "Отобрано: 10\n",
      "AUC на тесте: 0.7546\n",
      "accuracy: 0.69\n",
      "precision: 0.7166666666666667\n",
      "recall: 0.7543859649122807\n",
      "f1_score: 0.7350427350427351\n",
      "auc: 0.7545899632802937\n",
      "tp: 43\n",
      "tn: 26\n",
      "fp: 17\n",
      "fn: 14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------------- Data loading -----------------------\n",
    "def generate_game_raw(path_to_games_raw_dir=\"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        file_path = os.path.join(path_to_games_raw_dir, filename)\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game):\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        if len(team_players) != 2:\n",
    "            return False\n",
    "        for p_ids in team_players.values():\n",
    "            if len(set(p_ids)) != 5:\n",
    "                return False\n",
    "        team_ids = list(team_players.keys())\n",
    "        rounds = []\n",
    "        for r in game[\"rounds\"]:\n",
    "            if r[\"round\"] is None or r[\"ct\"] not in team_ids or r[\"terrorists\"] not in team_ids or r[\"winner_team\"] not in team_ids:\n",
    "                return False\n",
    "            rounds.append(r[\"round\"])\n",
    "        if min(rounds) != 1 or max(rounds) < 16:\n",
    "            return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir=\"data/games_raw\"):\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_y(path_to_games_raw, game_ids):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        file_path = os.path.join(path_to_games_raw, f\"{game_id}.json\")\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                game = json.load(f)\n",
    "            team_players = defaultdict(list)\n",
    "            for p in game[\"players\"]:\n",
    "                team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "            t1_id, t2_id = sorted(team_players.keys())\n",
    "            X.append([t1_id, t2_id] + sorted(team_players[t1_id]) + sorted(team_players[t2_id]))\n",
    "            team_win_count = {t1_id: 0, t2_id: 0}\n",
    "            for r in game[\"rounds\"]:\n",
    "                team_win_count[r[\"winner_team\"]] += 1\n",
    "            y.append(int(team_win_count[t1_id] > team_win_count[t2_id]))\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ----------------------- Column selector -----------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        return X[:, self.columns]\n",
    "\n",
    "# ----------------------- Bag encoders -----------------------\n",
    "class PlayerBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        uniques = np.unique(X.flatten())\n",
    "        self.player_dict = {player: idx for idx, player in enumerate(uniques)}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = len(self.player_dict)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, player in enumerate(row):\n",
    "                col_idx = self.player_dict.get(player)\n",
    "                if col_idx is not None:\n",
    "                    rows.append(i)\n",
    "                    cols.append(col_idx)\n",
    "                    data.append(1 if j < len(row)//2 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(n_samples, n_features), dtype=int)\n",
    "\n",
    "class TeamBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        uniques = np.unique(X.flatten())\n",
    "        self.team_dict = {team: idx for idx, team in enumerate(uniques)}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = len(self.team_dict)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, team in enumerate(row):\n",
    "                col_idx = self.team_dict.get(team)\n",
    "                if col_idx is not None:\n",
    "                    rows.append(i)\n",
    "                    cols.append(col_idx)\n",
    "                    data.append(1 if j == 0 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(n_samples, n_features), dtype=int)\n",
    "\n",
    "# ----------------------- Recursive L1 Selector -----------------------\n",
    "class RecursiveL1Selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, C=1, cv=None):\n",
    "        self.C = C\n",
    "        self.cv = cv        \n",
    "        self.features_mask_ = None\n",
    "    def fit(self, X, y):\n",
    "        X_dense = X.toarray() if sparse.issparse(X) else np.asarray(X)\n",
    "        mask_all = np.ones(X_dense.shape[1], dtype=bool)\n",
    "        iteration = 0\n",
    "        while True:\n",
    "            iteration += 1\n",
    "            print(f\"Итерация отбора признаков: {iteration}\")\n",
    "            print(f\"Отобрано: {mask_all.sum()}\")\n",
    "            masks = []\n",
    "            for train_idx, val_idx in self.cv.split(X_dense[:, mask_all]):\n",
    "                X_train, y_train = X_dense[train_idx][:, mask_all], y[train_idx]\n",
    "                model = LogisticRegression(solver=\"liblinear\", penalty=\"l1\",\n",
    "                                           C=self.C, max_iter=1000, random_state=42)\n",
    "                model.fit(X_train, y_train)\n",
    "                masks.append(model.coef_[0] != 0)\n",
    "            majority_mask = np.vstack(masks).mean(axis=0) >= 0.5\n",
    "            prev_sum = mask_all.sum()\n",
    "            mask_all[np.where(mask_all)[0][~majority_mask]] = False\n",
    "            if prev_sum == mask_all.sum():\n",
    "                break\n",
    "        self.features_mask_ = mask_all\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_dense = X.toarray() if sparse.issparse(X) else np.asarray(X)\n",
    "        return X_dense[:, self.features_mask_]\n",
    "    \n",
    "class PlayerEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k_factor=32, base_elo=1000):\n",
    "        self.k_factor = k_factor\n",
    "        self.base_elo = base_elo\n",
    "        self.elo_dict_ = {}\n",
    "        self.X_elo_train_ = None\n",
    "        self.X_shape_ = None\n",
    "\n",
    "    def _expected_score(self, rating_a, rating_b):\n",
    "        return 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n",
    "\n",
    "    def _augment_X(self, row):\n",
    "        \"\"\"\n",
    "        row: np.array с Elo игроков (10 элементов)\n",
    "        Возвращает новый вектор признаков:\n",
    "          - среднее Elo каждой команды\n",
    "          - разница средних Elo (team1 - team2)\n",
    "          - попарные разницы всех игроков между командами\n",
    "        \"\"\"\n",
    "        x1 = np.sort(row[:5])\n",
    "        x2 = np.sort(row[5:])\n",
    "        features = []\n",
    "\n",
    "        mean1 = np.mean(x1)\n",
    "        mean2 = np.mean(x2)\n",
    "        features.extend([mean1, mean2, mean1, -mean2, mean1 - mean2])\n",
    "\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                features.append(x1[i] - x2[j])\n",
    "\n",
    "        return np.array(features, dtype=float)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        X_elo = []\n",
    "\n",
    "        for row, outcome in tqdm(zip(X, y), total=X.shape[0], desc=\"Fitting PlayerEloEncoder\"):\n",
    "            elos_before = [self.elo_dict_.get(pid, self.base_elo) for pid in row]\n",
    "            X_elo.append(elos_before)\n",
    "\n",
    "            avg1 = np.mean(elos_before[:5])\n",
    "            avg2 = np.mean(elos_before[5:])\n",
    "            exp1 = self._expected_score(avg1, avg2)\n",
    "            score1 = 1 if outcome == 1 else 0\n",
    "            score2 = 1 - score1\n",
    "\n",
    "            for pid in row[:5]:\n",
    "                self.elo_dict_[pid] = self.elo_dict_.get(pid, self.base_elo) + self.k_factor * (score1 - exp1)\n",
    "            for pid in row[5:]:\n",
    "                self.elo_dict_[pid] = self.elo_dict_.get(pid, self.base_elo) + self.k_factor * (score2 - (1 - exp1))\n",
    "\n",
    "        self.X_elo_train_ = np.array(X_elo, dtype=float)\n",
    "        self.X_shape_ = X.shape\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        if hasattr(self, \"X_elo_train_\") and self.X_elo_train_ is not None and X.shape == getattr(self, \"X_shape_\", None):\n",
    "            X_out = np.copy(self.X_elo_train_)\n",
    "        else:\n",
    "            X_out = np.array([[self.elo_dict_.get(pid, self.base_elo) for pid in row] for row in X], dtype=float)\n",
    "\n",
    "        # всегда возвращаем расширённые признаки\n",
    "        X_aug = np.array([self._augment_X(row) for row in X_out], dtype=float)\n",
    "        return X_aug\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------- Metrics -----------------------\n",
    "def get_metrics(y_true, y_pred, y_proba):\n",
    "    acc = float(accuracy_score(y_true, y_pred))\n",
    "    prec = float(precision_score(y_true, y_pred))\n",
    "    rec = float(recall_score(y_true, y_pred))\n",
    "    f1 = float(f1_score(y_true, y_pred))\n",
    "    auc = float(roc_auc_score(y_true, y_proba))\n",
    "    tn, fp, fn, tp = map(int, confusion_matrix(y_true, y_pred).ravel())\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1_score\": f1, \"auc\": auc,\n",
    "            \"tp\": tp, \"tn\": tn, \"fp\": fp, \"fn\": fn}\n",
    "\n",
    "# ----------------------- Load data -----------------------\n",
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "X_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "team_cols = [0, 1]\n",
    "player_cols = list(range(2, X_train.shape[1]))\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"encoder\", FeatureUnion([\n",
    "        # (\"team_bag\", Pipeline([\n",
    "        #     (\"select_teams\", ColumnSelector(team_cols)),\n",
    "        #     (\"team_encoder\", TeamBagEncoder())\n",
    "        # ])),\n",
    "        # (\"player_bag\", Pipeline([\n",
    "        #     (\"select_players\", ColumnSelector(player_cols)),\n",
    "        #     (\"player_encoder\", PlayerBagEncoder())\n",
    "        # ])),\n",
    "        (\"player_elo\", Pipeline([\n",
    "            (\"select_players\", ColumnSelector(player_cols)),\n",
    "            (\"elo_encoder\", PlayerEloEncoder())\n",
    "        ]))\n",
    "    ])),   \n",
    "    (\"l1\", RecursiveL1Selector(C=1, cv=tscv)),    \n",
    "    (\"clf\", LogisticRegression(solver=\"liblinear\", C=1, random_state=42))\n",
    "])\n",
    "# ----------------------- Fit pipeline -----------------------\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "y_test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics = get_metrics(y_test, y_test_pred, y_test_proba)\n",
    "print(f\"AUC на тесте: {metrics['auc']:.4f}\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e95c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
