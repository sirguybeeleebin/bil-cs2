{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c9914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "from typing import Generator, Any\n",
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging as log\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder as SklearnLabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "log.basicConfig(level=log.INFO)\n",
    "\n",
    "# ------------------------------\n",
    "# DATA LOADING AND VALIDATION\n",
    "# ------------------------------\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\") -> Generator[dict[str, Any], None, None]:\n",
    "    for filename in os.listdir(path_to_games_raw_dir):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "\n",
    "        assert len(team_players) == 2\n",
    "        for t_id, p_ids in team_players.items():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        team_ids = list(team_players.keys())\n",
    "        rounds = []\n",
    "        for r in game[\"rounds\"]:\n",
    "            assert r[\"round\"] is not None\n",
    "            assert r[\"ct\"] in team_ids\n",
    "            assert r[\"terrorists\"] in team_ids\n",
    "            assert r[\"winner_team\"] in team_ids\n",
    "            rounds.append(r[\"round\"])\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid = []\n",
    "    game_begin_at_valid = []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "# ------------------------------\n",
    "# X, y PREPARATION\n",
    "# ------------------------------\n",
    "def get_player_id_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())    \n",
    "    X.extend(sorted(team_players[t1_id])) \n",
    "    X.extend(sorted(team_players[t2_id]))    \n",
    "    return X\n",
    "\n",
    "def get_team_id_X_for_game(path_to_games_raw_dir: str, game_id: int):    \n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    team_ids = sorted({p[\"team\"][\"id\"] for p in game[\"players\"]})\n",
    "    assert len(team_ids) == 2\n",
    "    return team_ids\n",
    "\n",
    "def get_game_info_X_for_game(path_to_games_raw_dir: str, game_id: int):    \n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    timestamp = parse(game[\"begin_at\"]).timestamp()\n",
    "    map_id = int(game[\"map\"][\"id\"])\n",
    "    league_id = int(game[\"match\"][\"league\"][\"id\"])\n",
    "    serie_id = int(game[\"match\"][\"serie\"][\"id\"])\n",
    "    serie_tier = game[\"match\"][\"serie\"].get(\"tier\", \"unknown\")\n",
    "    tournament_id = int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "    return [timestamp, map_id, league_id, serie_id, serie_tier, tournament_id]\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id:0, t2_id:0}\n",
    "    for r in game[\"rounds\"]:\n",
    "       team_win_count[r[\"winner_team\"]] += 1 \n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X_game_info, X_team_id, X_player_id, y = [], [], [], []\n",
    "    for game_id in game_ids:\n",
    "        try:\n",
    "            X_player_id.append(get_player_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_team_id.append(get_team_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_game_info.append(get_game_info_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except Exception as e:\n",
    "            log.warning(f\"Skipping game {game_id} due to error: {e}\")\n",
    "            continue\n",
    "    return (np.array(X_game_info, dtype=object),\n",
    "            np.array(X_team_id),\n",
    "            np.array(X_player_id),\n",
    "            np.array(y, dtype=int))\n",
    "\n",
    "# ------------------------------\n",
    "# CUSTOM TRANSFORMERS\n",
    "# ------------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array(X)[:, self.columns]\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoder = SklearnLabelEncoder()\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.encoder.fit(X.ravel().astype(object))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X).copy()\n",
    "        flat = X.ravel().astype(object)\n",
    "        mask = np.isin(flat, self.encoder.classes_)\n",
    "        flat_result = np.full(flat.shape, -1, dtype=int)\n",
    "        flat_result[mask] = self.encoder.transform(flat[mask])\n",
    "        return flat_result.reshape(X.shape)\n",
    "\n",
    "class PlayerBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.d = {val: idx for idx, val in enumerate(np.unique(X.flatten()))}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, val in enumerate(row):\n",
    "                if val in self.d:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.d[val])\n",
    "                    data.append(1 if j < 5 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(X.shape[0], len(self.d)), dtype=int)\n",
    "\n",
    "class TeamBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.d = {val: idx for idx, val in enumerate(np.unique(X.flatten()))}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, val in enumerate(row):\n",
    "                if val in self.d:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.d[val])\n",
    "                    data.append(1 if j == 0 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(X.shape[0], len(self.d)), dtype=int)\n",
    "\n",
    "class GameInfoEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.array(X, dtype=object)\n",
    "        self.scaler = MinMaxScaler().fit(X[:, [0]])\n",
    "        self.ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore').fit(X[:, 1:])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.array(X, dtype=object)\n",
    "        ts_scaled = self.scaler.transform(X[:, [0]])\n",
    "        cat_ohe = self.ohe.transform(X[:, 1:])\n",
    "        return sparse.hstack([ts_scaled, cat_ohe]).tocsr()\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "def perm_importance_worker(estimator, X_val, y_val, i, baseline, random_seed):\n",
    "    col = X_val[:, i].copy()\n",
    "    if sparse.issparse(col):\n",
    "        col = col.toarray().ravel()\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    rng.shuffle(col)\n",
    "\n",
    "    X_perm = X_val.copy()\n",
    "    if sparse.issparse(X_perm):\n",
    "        X_perm = X_perm.tolil()\n",
    "        X_perm[:, i] = col.reshape(-1, 1)\n",
    "        X_perm = X_perm.tocsr()\n",
    "    else:\n",
    "        X_perm[:, i] = col\n",
    "\n",
    "    perm_score = roc_auc_score(y_val, estimator.predict_proba(X_perm)[:, 1])\n",
    "    return baseline - perm_score\n",
    "\n",
    "\n",
    "class SparsePermutationImportanceFeatureSelector:\n",
    "    def __init__(self, estimator=None, scoring=roc_auc_score, random_state=42, n_jobs=-1):\n",
    "        self.estimator = estimator if estimator else LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "        self.scoring = scoring\n",
    "        self.random_state = random_state\n",
    "        self.feature_importances_ = None\n",
    "        self.n_jobs = n_jobs  # —á–∏—Å–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not sparse.issparse(X):\n",
    "            X = sparse.csr_matrix(X)\n",
    "\n",
    "        mask = np.arange(X.shape[1])\n",
    "        iteration = 0\n",
    "        best_score = -np.inf\n",
    "        best_mask = mask.copy()\n",
    "        n_splits = 10\n",
    "\n",
    "        while True:\n",
    "            iteration += 1\n",
    "            print(f\"\\n=== –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration} ===\")\n",
    "            X_subset = X[:, mask]\n",
    "            print(f\"–¢–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_subset.shape[1]}\")\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "            fold_importances_list = []\n",
    "            fold_scores = []\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X_subset)):\n",
    "                print(f\"\\n--- Fold {fold_idx + 1}/{n_splits} ---\")\n",
    "                X_train, X_val = X_subset[train_idx], X_subset[val_idx]\n",
    "                y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                self.estimator.fit(X_train, y_train)\n",
    "                baseline = self.scoring(y_val, self.estimator.predict_proba(X_val)[:, 1])\n",
    "                fold_scores.append(baseline)\n",
    "                print(f\"ROC-AUC –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {baseline:.4f}\")\n",
    "\n",
    "                # –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ permutation importance –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "                fold_importances = Parallel(n_jobs=self.n_jobs)(\n",
    "                    delayed(perm_importance_worker)(self.estimator, X_val, y_val, i, baseline, self.random_state + fold_idx)\n",
    "                    for i in range(X_subset.shape[1])\n",
    "                )\n",
    "                fold_importances = np.array(fold_importances)\n",
    "                print(f\"–°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ fold {fold_idx + 1}: {np.mean(fold_importances):.6f}\")\n",
    "                fold_importances_list.append(fold_importances)\n",
    "\n",
    "            mean_importances = np.mean(fold_importances_list, axis=0)\n",
    "            avg_score = np.mean(fold_scores)\n",
    "            print(f\"\\n–°—Ä–µ–¥–Ω–∏–π ROC-AUC –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º: {avg_score:.4f}\")\n",
    "            print(f\"–°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º: {np.mean(mean_importances):.6f}\")\n",
    "\n",
    "            if avg_score < best_score:\n",
    "                print(f\"–°—Ä–µ–¥–Ω—è—è –º–µ—Ç—Ä–∏–∫–∞ —É–ø–∞–ª–∞ —Å {best_score:.4f} –¥–æ {avg_score:.4f}. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é.\")\n",
    "                mask = best_mask\n",
    "                break\n",
    "\n",
    "            best_score = avg_score\n",
    "            best_mask = mask.copy()\n",
    "\n",
    "            positive_mask = mean_importances > 0\n",
    "            n_positive = np.sum(positive_mask)\n",
    "            print(f\"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é: {n_positive} –∏–∑ {len(mean_importances)}\")\n",
    "\n",
    "            if n_positive == X_subset.shape[1]:\n",
    "                print(\"–í—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–º–µ—é—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –≤–∞–∂–Ω–æ—Å—Ç—å. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é.\")\n",
    "                break\n",
    "\n",
    "            mask = mask[positive_mask]\n",
    "            print(f\"–£–¥–∞–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω—É–ª–µ–≤–æ–π –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é, –æ—Å—Ç–∞–≤–ª—è–µ–º {len(mask)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "\n",
    "        self.feature_importances_ = np.zeros(X.shape[1])\n",
    "        self.feature_importances_[mask] = 1\n",
    "        print(\"\\n–ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—ã—á–∏—Å–ª–µ–Ω–∞!\")\n",
    "        print(f\"–û—Å—Ç–∞–≤–ª–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {np.sum(self.feature_importances_)} –∏–∑ {X.shape[1]}\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mask = self.feature_importances_ > 0\n",
    "        print(f\"–í—ã–±—Ä–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é: {np.sum(mask)} –∏–∑ {len(mask)}\")\n",
    "        if not sparse.issparse(X):\n",
    "            X = sparse.csr_matrix(X)\n",
    "        return X[:, mask]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "    \n",
    "class PlayerStatSumFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}\n",
    "\n",
    "    def _get_player_stat(self, game_id: int) -> dict:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        return {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        n_games = X.shape[0]\n",
    "        X_cumulative = np.zeros((n_games, 10), dtype=int)\n",
    "        for i in range(n_games):\n",
    "            game_id = self.game_ids[i]\n",
    "            player_ids = X[i]\n",
    "            player_stat_game = self._get_player_stat(game_id)\n",
    "            row_stat = []\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + player_stat_game.get(p_id, 0)\n",
    "                row_stat.append(self.cumulative_dict[p_id])\n",
    "            X_cumulative[i, :] = row_stat\n",
    "        self.X_cumulative_train = X_cumulative\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_games = X.shape[0]\n",
    "        if hasattr(self, \"X_cumulative_train\") and self.X_cumulative_train.shape[0] == n_games:\n",
    "            X_cumulative = self.X_cumulative_train\n",
    "        else:\n",
    "            X_cumulative = np.zeros((n_games, 10), dtype=int)\n",
    "            for i in range(n_games):\n",
    "                X_cumulative[i, :] = np.array([self.cumulative_dict.get(p_id, 0) for p_id in X[i]])\n",
    "        first5_sorted = np.sort(X_cumulative[:, :5], axis=1)\n",
    "        last5_sorted = np.sort(X_cumulative[:, 5:], axis=1)\n",
    "        x = np.hstack([first5_sorted, last5_sorted])\n",
    "        mean_first5 = np.mean(first5_sorted, axis=1).reshape(-1, 1)\n",
    "        mean_last5 = np.mean(last5_sorted, axis=1).reshape(-1, 1)\n",
    "        diff_means = mean_first5 - mean_last5\n",
    "        x = np.hstack([x, mean_first5, mean_last5, diff_means])\n",
    "        pairwise_diffs = np.zeros((n_games, 25))\n",
    "        for row_id in range(x.shape[0]):\n",
    "            c = 0\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    pairwise_diffs[row_id, c] = first5_sorted[row_id, i] - last5_sorted[row_id, j]\n",
    "                    c += 1\n",
    "        x = np.hstack([x, pairwise_diffs])\n",
    "        return x\n",
    "\n",
    "class PlayerStatMeanFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}  # stores cumulative sum\n",
    "        self.count_dict = {}       # stores counts for mean calculation\n",
    "\n",
    "    def _get_player_stat(self, game_id: int) -> dict:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        return {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        n_games = X.shape[0]\n",
    "        X_mean = np.zeros((n_games, 10), dtype=float)\n",
    "        for i in range(n_games):\n",
    "            game_id = self.game_ids[i]\n",
    "            player_ids = X[i]\n",
    "            player_stat_game = self._get_player_stat(game_id)\n",
    "            row_stat = []\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + player_stat_game.get(p_id, 0)\n",
    "                self.count_dict[p_id] = self.count_dict.get(p_id, 0) + 1\n",
    "                row_stat.append(self.cumulative_dict[p_id] / self.count_dict[p_id])\n",
    "            X_mean[i, :] = row_stat\n",
    "        self.X_mean_train = X_mean\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_games = X.shape[0]\n",
    "        if hasattr(self, \"X_mean_train\") and self.X_mean_train.shape[0] == n_games:\n",
    "            X_mean = self.X_mean_train\n",
    "        else:\n",
    "            X_mean = np.zeros((n_games, 10), dtype=float)\n",
    "            for i in range(n_games):\n",
    "                X_mean[i, :] = np.array([\n",
    "                    self.cumulative_dict.get(p_id, 0) / max(self.count_dict.get(p_id, 1), 1) \n",
    "                    for p_id in X[i]\n",
    "                ])\n",
    "        first5_sorted = np.sort(X_mean[:, :5], axis=1)\n",
    "        last5_sorted = np.sort(X_mean[:, 5:], axis=1)\n",
    "        x = np.hstack([first5_sorted, last5_sorted])\n",
    "        mean_first5 = np.mean(first5_sorted, axis=1).reshape(-1, 1)\n",
    "        mean_last5 = np.mean(last5_sorted, axis=1).reshape(-1, 1)\n",
    "        diff_means = mean_first5 - mean_last5\n",
    "        x = np.hstack([x, mean_first5, mean_last5, diff_means])\n",
    "        pairwise_diffs = np.zeros((n_games, 25))\n",
    "        for row_id in range(x.shape[0]):\n",
    "            c = 0\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    pairwise_diffs[row_id, c] = first5_sorted[row_id, i] - last5_sorted[row_id, j]\n",
    "                    c += 1\n",
    "        x = np.hstack([x, pairwise_diffs])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c68f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏...\n",
      "\n",
      "üöÄ –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞...\n",
      "\n",
      "=== –ò—Ç–µ—Ä–∞—Ü–∏—è 1 ===\n",
      "–¢–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 9981\n",
      "\n",
      "--- Fold 1/10 ---\n",
      "ROC-AUC –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: 0.6972\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "TIMESTAMP_COL = [0]\n",
    "GAME_INFO_COL = [1, 2, 3, 4, 5]\n",
    "TEAM_ID_COL = [6, 7]\n",
    "PLAYER_ID_COL = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            # –ò–≥—Ä–æ–∫–∏\n",
    "            ('players', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                ('le', LabelEncoder()),\n",
    "                ('bag', PlayerBagEncoder())\n",
    "            ])),\n",
    "            \n",
    "            # –ö–æ–º–∞–Ω–¥—ã\n",
    "            ('teams', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=TEAM_ID_COL)),\n",
    "                ('le', LabelEncoder()),\n",
    "                ('bag', TeamBagEncoder())\n",
    "            ])),\n",
    "\n",
    "            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞—Ç—á–µ\n",
    "            ('game_info', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=TIMESTAMP_COL + GAME_INFO_COL)),\n",
    "                ('transform', GameInfoEncoder())  \n",
    "            ])),\n",
    "\n",
    "            # –°—É–º–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–∞–∑–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–≥—Ä–æ–∫–æ–≤\n",
    "            *[\n",
    "                (f\"{key}_sum\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_sum\", PlayerStatSumFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in [\"kills\", \"deaths\", \"assists\", \"headshots\", \"flash_assists\"]\n",
    "            ],\n",
    "\n",
    "            # –°—Ä–µ–¥–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–≥—Ä–æ–∫–æ–≤ + —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏\n",
    "            *[\n",
    "                (f\"{key}_mean\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_mean\", PlayerStatMeanFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in [\n",
    "                    \"kills\", \"deaths\", \"assists\", \"headshots\", \"flash_assists\",\n",
    "                    \"first_kills_diff\", \"k_d_diff\", \"adr\", \"kast\", \"rating\"\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    ('perm_selector', SparsePermutationImportanceFeatureSelector(\n",
    "        estimator=LogisticRegression(solver=\"liblinear\", random_state=42),\n",
    "        scoring=roc_auc_score,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # RFECV –¥–ª—è –æ—Ç–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "    ('rfecv', RFECV(\n",
    "        estimator=LogisticRegression(solver=\"liblinear\", random_state=42),\n",
    "        step=1,\n",
    "        cv=TimeSeriesSplit(n_splits=10),\n",
    "        scoring='roc_auc',\n",
    "        min_features_to_select=1,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "    ('clf', LogisticRegression(solver=\"liblinear\", random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# –û–ë–£–ß–ï–ù–ò–ï –ò –û–¶–ï–ù–ö–ê\n",
    "# ======================================================\n",
    "print(\"\\nüì• –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏...\")\n",
    "X_game_info_train, X_team_id_train, X_player_id_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_game_info_test, X_team_id_test, X_player_id_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "# –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ X\n",
    "X_train = np.c_[X_game_info_train, X_team_id_train, X_player_id_train]\n",
    "X_test = np.c_[X_game_info_test, X_team_id_test, X_player_id_test]\n",
    "\n",
    "print(\"\\nüöÄ –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nüéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ...\")\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ======================================================\n",
    "# –†–ï–ó–£–õ–¨–¢–ê–¢–´\n",
    "# ======================================================\n",
    "print(\"\\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–û–î–ï–õ–ò:\")\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score : {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC  : {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "print(\"\\n–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf36d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
