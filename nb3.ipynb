{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c9914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "from typing import Generator, Any\n",
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging as log\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder as SklearnLabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "log.basicConfig(level=log.INFO)\n",
    "\n",
    "# ------------------------------\n",
    "# DATA LOADING AND VALIDATION\n",
    "# ------------------------------\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\") -> Generator[dict[str, Any], None, None]:\n",
    "    for filename in os.listdir(path_to_games_raw_dir):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "\n",
    "        assert len(team_players) == 2\n",
    "        for t_id, p_ids in team_players.items():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        team_ids = list(team_players.keys())\n",
    "        rounds = []\n",
    "        for r in game[\"rounds\"]:\n",
    "            assert r[\"round\"] is not None\n",
    "            assert r[\"ct\"] in team_ids\n",
    "            assert r[\"terrorists\"] in team_ids\n",
    "            assert r[\"winner_team\"] in team_ids\n",
    "            rounds.append(r[\"round\"])\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid = []\n",
    "    game_begin_at_valid = []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "# ------------------------------\n",
    "# X, y PREPARATION\n",
    "# ------------------------------\n",
    "def get_player_id_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())    \n",
    "    X.extend(sorted(team_players[t1_id])) \n",
    "    X.extend(sorted(team_players[t2_id]))    \n",
    "    return X\n",
    "\n",
    "def get_team_id_X_for_game(path_to_games_raw_dir: str, game_id: int):    \n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    team_ids = sorted({p[\"team\"][\"id\"] for p in game[\"players\"]})\n",
    "    assert len(team_ids) == 2\n",
    "    return team_ids\n",
    "\n",
    "def get_game_info_X_for_game(path_to_games_raw_dir: str, game_id: int):    \n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    timestamp = parse(game[\"begin_at\"]).timestamp()\n",
    "    map_id = int(game[\"map\"][\"id\"])\n",
    "    league_id = int(game[\"match\"][\"league\"][\"id\"])\n",
    "    serie_id = int(game[\"match\"][\"serie\"][\"id\"])\n",
    "    serie_tier = game[\"match\"][\"serie\"].get(\"tier\", \"unknown\")\n",
    "    tournament_id = int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "    return [timestamp, map_id, league_id, serie_id, serie_tier, tournament_id]\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id:0, t2_id:0}\n",
    "    for r in game[\"rounds\"]:\n",
    "       team_win_count[r[\"winner_team\"]] += 1 \n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X_game_info, X_team_id, X_player_id, y = [], [], [], []\n",
    "    for game_id in game_ids:\n",
    "        try:\n",
    "            X_player_id.append(get_player_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_team_id.append(get_team_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_game_info.append(get_game_info_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except Exception as e:\n",
    "            log.warning(f\"Skipping game {game_id} due to error: {e}\")\n",
    "            continue\n",
    "    return (np.array(X_game_info, dtype=object),\n",
    "            np.array(X_team_id),\n",
    "            np.array(X_player_id),\n",
    "            np.array(y, dtype=int))\n",
    "\n",
    "# ------------------------------\n",
    "# CUSTOM TRANSFORMERS\n",
    "# ------------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array(X)[:, self.columns]\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoder = SklearnLabelEncoder()\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.encoder.fit(X.ravel().astype(object))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X).copy()\n",
    "        flat = X.ravel().astype(object)\n",
    "        mask = np.isin(flat, self.encoder.classes_)\n",
    "        flat_result = np.full(flat.shape, -1, dtype=int)\n",
    "        flat_result[mask] = self.encoder.transform(flat[mask])\n",
    "        return flat_result.reshape(X.shape)\n",
    "\n",
    "class PlayerBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.d = {val: idx for idx, val in enumerate(np.unique(X.flatten()))}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, val in enumerate(row):\n",
    "                if val in self.d:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.d[val])\n",
    "                    data.append(1 if j < 5 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(X.shape[0], len(self.d)), dtype=int)\n",
    "\n",
    "class TeamBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.d = {val: idx for idx, val in enumerate(np.unique(X.flatten()))}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, val in enumerate(row):\n",
    "                if val in self.d:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.d[val])\n",
    "                    data.append(1 if j == 0 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(X.shape[0], len(self.d)), dtype=int)\n",
    "\n",
    "class GameInfoEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.array(X, dtype=object)\n",
    "        self.scaler = MinMaxScaler().fit(X[:, [0]])\n",
    "        self.ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore').fit(X[:, 1:])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.array(X, dtype=object)\n",
    "        ts_scaled = self.scaler.transform(X[:, [0]])\n",
    "        cat_ohe = self.ohe.transform(X[:, 1:])\n",
    "        return sparse.hstack([ts_scaled, cat_ohe]).tocsr()\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# функция для одного признака\n",
    "def perm_importance_worker(estimator, X_val, y_val, i, baseline, random_seed):\n",
    "    col = X_val[:, i].copy()\n",
    "    if sparse.issparse(col):\n",
    "        col = col.toarray().ravel()\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    rng.shuffle(col)\n",
    "\n",
    "    X_perm = X_val.copy()\n",
    "    if sparse.issparse(X_perm):\n",
    "        X_perm = X_perm.tolil()\n",
    "        X_perm[:, i] = col.reshape(-1, 1)\n",
    "        X_perm = X_perm.tocsr()\n",
    "    else:\n",
    "        X_perm[:, i] = col\n",
    "\n",
    "    perm_score = roc_auc_score(y_val, estimator.predict_proba(X_perm)[:, 1])\n",
    "    return baseline - perm_score\n",
    "\n",
    "\n",
    "class SparsePermutationImportanceFeatureSelector:\n",
    "    def __init__(self, estimator=None, scoring=roc_auc_score, random_state=42, n_jobs=-1):\n",
    "        self.estimator = estimator if estimator else LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "        self.scoring = scoring\n",
    "        self.random_state = random_state\n",
    "        self.feature_importances_ = None\n",
    "        self.n_jobs = n_jobs  # число параллельных процессов\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not sparse.issparse(X):\n",
    "            X = sparse.csr_matrix(X)\n",
    "\n",
    "        mask = np.arange(X.shape[1])\n",
    "        iteration = 0\n",
    "        best_score = -np.inf\n",
    "        best_mask = mask.copy()\n",
    "        n_splits = 10\n",
    "\n",
    "        while True:\n",
    "            iteration += 1\n",
    "            print(f\"\\n=== Итерация {iteration} ===\")\n",
    "            X_subset = X[:, mask]\n",
    "            print(f\"Текущий размер признаков: {X_subset.shape[1]}\")\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "            fold_importances_list = []\n",
    "            fold_scores = []\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X_subset)):\n",
    "                print(f\"\\n--- Fold {fold_idx + 1}/{n_splits} ---\")\n",
    "                X_train, X_val = X_subset[train_idx], X_subset[val_idx]\n",
    "                y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                self.estimator.fit(X_train, y_train)\n",
    "                baseline = self.scoring(y_val, self.estimator.predict_proba(X_val)[:, 1])\n",
    "                fold_scores.append(baseline)\n",
    "                print(f\"ROC-AUC на валидации: {baseline:.4f}\")\n",
    "\n",
    "                # параллельное вычисление permutation importance по признакам\n",
    "                fold_importances = Parallel(n_jobs=self.n_jobs)(\n",
    "                    delayed(perm_importance_worker)(self.estimator, X_val, y_val, i, baseline, self.random_state + fold_idx)\n",
    "                    for i in range(X_subset.shape[1])\n",
    "                )\n",
    "                fold_importances = np.array(fold_importances)\n",
    "                print(f\"Средняя важность признаков в fold {fold_idx + 1}: {np.mean(fold_importances):.6f}\")\n",
    "                fold_importances_list.append(fold_importances)\n",
    "\n",
    "            mean_importances = np.mean(fold_importances_list, axis=0)\n",
    "            avg_score = np.mean(fold_scores)\n",
    "            print(f\"\\nСредний ROC-AUC по всем фолдам: {avg_score:.4f}\")\n",
    "            print(f\"Средняя важность признаков по всем фолдам: {np.mean(mean_importances):.6f}\")\n",
    "\n",
    "            if avg_score < best_score:\n",
    "                print(f\"Средняя метрика упала с {best_score:.4f} до {avg_score:.4f}. Останавливаем рекурсию.\")\n",
    "                mask = best_mask\n",
    "                break\n",
    "\n",
    "            best_score = avg_score\n",
    "            best_mask = mask.copy()\n",
    "\n",
    "            positive_mask = mean_importances > 0\n",
    "            n_positive = np.sum(positive_mask)\n",
    "            print(f\"Признаков с положительной важностью: {n_positive} из {len(mean_importances)}\")\n",
    "\n",
    "            if n_positive == X_subset.shape[1]:\n",
    "                print(\"Все оставшиеся признаки имеют положительную важность. Останавливаем рекурсию.\")\n",
    "                break\n",
    "\n",
    "            mask = mask[positive_mask]\n",
    "            print(f\"Удаляем признаки с нулевой или отрицательной важностью, оставляем {len(mask)} признаков\")\n",
    "\n",
    "        self.feature_importances_ = np.zeros(X.shape[1])\n",
    "        self.feature_importances_[mask] = 1\n",
    "        print(\"\\nПерестановочная важность признаков вычислена!\")\n",
    "        print(f\"Оставлено признаков: {np.sum(self.feature_importances_)} из {X.shape[1]}\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mask = self.feature_importances_ > 0\n",
    "        print(f\"Выбраны признаки с положительной важностью: {np.sum(mask)} из {len(mask)}\")\n",
    "        if not sparse.issparse(X):\n",
    "            X = sparse.csr_matrix(X)\n",
    "        return X[:, mask]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "    \n",
    "class PlayerStatSumFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}\n",
    "\n",
    "    def _get_player_stat(self, game_id: int) -> dict:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        return {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        n_games = X.shape[0]\n",
    "        X_cumulative = np.zeros((n_games, 10), dtype=int)\n",
    "        for i in range(n_games):\n",
    "            game_id = self.game_ids[i]\n",
    "            player_ids = X[i]\n",
    "            player_stat_game = self._get_player_stat(game_id)\n",
    "            row_stat = []\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + player_stat_game.get(p_id, 0)\n",
    "                row_stat.append(self.cumulative_dict[p_id])\n",
    "            X_cumulative[i, :] = row_stat\n",
    "        self.X_cumulative_train = X_cumulative\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_games = X.shape[0]\n",
    "        if hasattr(self, \"X_cumulative_train\") and self.X_cumulative_train.shape[0] == n_games:\n",
    "            X_cumulative = self.X_cumulative_train\n",
    "        else:\n",
    "            X_cumulative = np.zeros((n_games, 10), dtype=int)\n",
    "            for i in range(n_games):\n",
    "                X_cumulative[i, :] = np.array([self.cumulative_dict.get(p_id, 0) for p_id in X[i]])\n",
    "        first5_sorted = np.sort(X_cumulative[:, :5], axis=1)\n",
    "        last5_sorted = np.sort(X_cumulative[:, 5:], axis=1)\n",
    "        x = np.hstack([first5_sorted, last5_sorted])\n",
    "        mean_first5 = np.mean(first5_sorted, axis=1).reshape(-1, 1)\n",
    "        mean_last5 = np.mean(last5_sorted, axis=1).reshape(-1, 1)\n",
    "        diff_means = mean_first5 - mean_last5\n",
    "        x = np.hstack([x, mean_first5, mean_last5, diff_means])\n",
    "        pairwise_diffs = np.zeros((n_games, 25))\n",
    "        for row_id in range(x.shape[0]):\n",
    "            c = 0\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    pairwise_diffs[row_id, c] = first5_sorted[row_id, i] - last5_sorted[row_id, j]\n",
    "                    c += 1\n",
    "        x = np.hstack([x, pairwise_diffs])\n",
    "        return x\n",
    "\n",
    "class PlayerStatMeanFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}  # stores cumulative sum\n",
    "        self.count_dict = {}       # stores counts for mean calculation\n",
    "\n",
    "    def _get_player_stat(self, game_id: int) -> dict:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        return {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        n_games = X.shape[0]\n",
    "        X_mean = np.zeros((n_games, 10), dtype=float)\n",
    "        for i in range(n_games):\n",
    "            game_id = self.game_ids[i]\n",
    "            player_ids = X[i]\n",
    "            player_stat_game = self._get_player_stat(game_id)\n",
    "            row_stat = []\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + player_stat_game.get(p_id, 0)\n",
    "                self.count_dict[p_id] = self.count_dict.get(p_id, 0) + 1\n",
    "                row_stat.append(self.cumulative_dict[p_id] / self.count_dict[p_id])\n",
    "            X_mean[i, :] = row_stat\n",
    "        self.X_mean_train = X_mean\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        n_games = X.shape[0]\n",
    "        if hasattr(self, \"X_mean_train\") and self.X_mean_train.shape[0] == n_games:\n",
    "            X_mean = self.X_mean_train\n",
    "        else:\n",
    "            X_mean = np.zeros((n_games, 10), dtype=float)\n",
    "            for i in range(n_games):\n",
    "                X_mean[i, :] = np.array([\n",
    "                    self.cumulative_dict.get(p_id, 0) / max(self.count_dict.get(p_id, 1), 1) \n",
    "                    for p_id in X[i]\n",
    "                ])\n",
    "        first5_sorted = np.sort(X_mean[:, :5], axis=1)\n",
    "        last5_sorted = np.sort(X_mean[:, 5:], axis=1)\n",
    "        x = np.hstack([first5_sorted, last5_sorted])\n",
    "        mean_first5 = np.mean(first5_sorted, axis=1).reshape(-1, 1)\n",
    "        mean_last5 = np.mean(last5_sorted, axis=1).reshape(-1, 1)\n",
    "        diff_means = mean_first5 - mean_last5\n",
    "        x = np.hstack([x, mean_first5, mean_last5, diff_means])\n",
    "        pairwise_diffs = np.zeros((n_games, 25))\n",
    "        for row_id in range(x.shape[0]):\n",
    "            c = 0\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    pairwise_diffs[row_id, c] = first5_sorted[row_id, i] - last5_sorted[row_id, j]\n",
    "                    c += 1\n",
    "        x = np.hstack([x, pairwise_diffs])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c68f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📥 Загружаем обучающую и тестовую выборки...\n",
      "\n",
      "🚀 Обучение пайплайна...\n",
      "\n",
      "=== Итерация 1 ===\n",
      "Текущий размер признаков: 9981\n",
      "\n",
      "--- Fold 1/10 ---\n",
      "ROC-AUC на валидации: 0.6972\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "TIMESTAMP_COL = [0]\n",
    "GAME_INFO_COL = [1, 2, 3, 4, 5]\n",
    "TEAM_ID_COL = [6, 7]\n",
    "PLAYER_ID_COL = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            # Игроки\n",
    "            ('players', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                ('le', LabelEncoder()),\n",
    "                ('bag', PlayerBagEncoder())\n",
    "            ])),\n",
    "            \n",
    "            # Команды\n",
    "            ('teams', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=TEAM_ID_COL)),\n",
    "                ('le', LabelEncoder()),\n",
    "                ('bag', TeamBagEncoder())\n",
    "            ])),\n",
    "\n",
    "            # Информация о матче\n",
    "            ('game_info', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=TIMESTAMP_COL + GAME_INFO_COL)),\n",
    "                ('transform', GameInfoEncoder())  \n",
    "            ])),\n",
    "\n",
    "            # Суммированные базовые статистики игроков\n",
    "            *[\n",
    "                (f\"{key}_sum\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_sum\", PlayerStatSumFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in [\"kills\", \"deaths\", \"assists\", \"headshots\", \"flash_assists\"]\n",
    "            ],\n",
    "\n",
    "            # Средние статистики игроков + расширенные показатели\n",
    "            *[\n",
    "                (f\"{key}_mean\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_mean\", PlayerStatMeanFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in [\n",
    "                    \"kills\", \"deaths\", \"assists\", \"headshots\", \"flash_assists\",\n",
    "                    \"first_kills_diff\", \"k_d_diff\", \"adr\", \"kast\", \"rating\"\n",
    "                ]\n",
    "            ]\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    # Перестановочная важность признаков\n",
    "    ('perm_selector', SparsePermutationImportanceFeatureSelector(\n",
    "        estimator=LogisticRegression(solver=\"liblinear\", random_state=42),\n",
    "        scoring=roc_auc_score,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # RFECV для отбора признаков\n",
    "    ('rfecv', RFECV(\n",
    "        estimator=LogisticRegression(solver=\"liblinear\", random_state=42),\n",
    "        step=1,\n",
    "        cv=TimeSeriesSplit(n_splits=10),\n",
    "        scoring='roc_auc',\n",
    "        min_features_to_select=1,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # Финальный классификатор\n",
    "    ('clf', LogisticRegression(solver=\"liblinear\", random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# ОБУЧЕНИЕ И ОЦЕНКА\n",
    "# ======================================================\n",
    "print(\"\\n📥 Загружаем обучающую и тестовую выборки...\")\n",
    "X_game_info_train, X_team_id_train, X_player_id_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_game_info_test, X_team_id_test, X_player_id_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "# объединяем все части X\n",
    "X_train = np.c_[X_game_info_train, X_team_id_train, X_player_id_train]\n",
    "X_test = np.c_[X_game_info_test, X_team_id_test, X_player_id_test]\n",
    "\n",
    "print(\"\\n🚀 Обучение пайплайна...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n🎯 Предсказание на тестовой выборке...\")\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ======================================================\n",
    "# РЕЗУЛЬТАТЫ\n",
    "# ======================================================\n",
    "print(\"\\n✅ РЕЗУЛЬТАТЫ МОДЕЛИ:\")\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score : {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC  : {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf36d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
