{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19c9914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "from typing import Generator, Any\n",
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import warnings\n",
    "import logging as log\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder as SklearnLabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "log.basicConfig(level=log.INFO)\n",
    "\n",
    "# ------------------------------\n",
    "# DATA LOADING AND VALIDATION\n",
    "# ------------------------------\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\") -> Generator[dict[str, Any], None, None]:\n",
    "    for filename in os.listdir(path_to_games_raw_dir):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "\n",
    "        assert len(team_players) == 2\n",
    "        for t_id, p_ids in team_players.items():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        team_ids = list(team_players.keys())\n",
    "        rounds = []\n",
    "        for r in game[\"rounds\"]:\n",
    "            assert r[\"round\"] is not None\n",
    "            assert r[\"ct\"] in team_ids\n",
    "            assert r[\"terrorists\"] in team_ids\n",
    "            assert r[\"winner_team\"] in team_ids\n",
    "            rounds.append(r[\"round\"])\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid = []\n",
    "    game_begin_at_valid = []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "# ------------------------------\n",
    "# X, y PREPARATION\n",
    "# ------------------------------\n",
    "def get_player_id_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())    \n",
    "    X.extend(sorted(team_players[t1_id])) \n",
    "    X.extend(sorted(team_players[t2_id]))    \n",
    "    return X\n",
    "\n",
    "def get_team_id_X_for_game(path_to_games_raw_dir: str, game_id: int):    \n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    team_ids = sorted({p[\"team\"][\"id\"] for p in game[\"players\"]})\n",
    "    assert len(team_ids) == 2\n",
    "    return team_ids\n",
    "\n",
    "def get_game_info_X_for_game(path_to_games_raw_dir: str, game_id: int):    \n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    timestamp = parse(game[\"begin_at\"]).timestamp()\n",
    "    map_id = int(game[\"map\"][\"id\"])\n",
    "    league_id = int(game[\"match\"][\"league\"][\"id\"])\n",
    "    serie_id = int(game[\"match\"][\"serie\"][\"id\"])\n",
    "    serie_tier = game[\"match\"][\"serie\"].get(\"tier\", \"unknown\")\n",
    "    tournament_id = int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "    return [timestamp, map_id, league_id, serie_id, serie_tier, tournament_id]\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id:0, t2_id:0}\n",
    "    for r in game[\"rounds\"]:\n",
    "       team_win_count[r[\"winner_team\"]] += 1 \n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X_game_info, X_team_id, X_player_id, y = [], [], [], []\n",
    "    for game_id in game_ids:\n",
    "        try:\n",
    "            X_player_id.append(get_player_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_team_id.append(get_team_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_game_info.append(get_game_info_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except Exception as e:\n",
    "            log.warning(f\"Skipping game {game_id} due to error: {e}\")\n",
    "            continue\n",
    "    return (np.array(X_game_info, dtype=object),\n",
    "            np.array(X_team_id),\n",
    "            np.array(X_player_id),\n",
    "            np.array(y, dtype=int))\n",
    "\n",
    "# ------------------------------\n",
    "# CUSTOM TRANSFORMERS\n",
    "# ------------------------------\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return np.array(X)[:, self.columns]\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoder = SklearnLabelEncoder()\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.encoder.fit(X.ravel().astype(object))\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X).copy()\n",
    "        flat = X.ravel().astype(object)\n",
    "        mask = np.isin(flat, self.encoder.classes_)\n",
    "        flat_result = np.full(flat.shape, -1, dtype=int)\n",
    "        flat_result[mask] = self.encoder.transform(flat[mask])\n",
    "        return flat_result.reshape(X.shape)\n",
    "\n",
    "class PlayerBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.d = {val: idx for idx, val in enumerate(np.unique(X.flatten()))}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, val in enumerate(row):\n",
    "                if val in self.d:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.d[val])\n",
    "                    data.append(1 if j < 5 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(X.shape[0], len(self.d)), dtype=int)\n",
    "\n",
    "class TeamBagEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.asarray(X)\n",
    "        self.d = {val: idx for idx, val in enumerate(np.unique(X.flatten()))}\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X)\n",
    "        rows, cols, data = [], [], []\n",
    "        for i, row in enumerate(X):\n",
    "            for j, val in enumerate(row):\n",
    "                if val in self.d:\n",
    "                    rows.append(i)\n",
    "                    cols.append(self.d[val])\n",
    "                    data.append(1 if j == 0 else -1)\n",
    "        return sparse.csr_matrix((data, (rows, cols)), shape=(X.shape[0], len(self.d)), dtype=int)\n",
    "\n",
    "class GameInfoEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        X = np.array(X, dtype=object)\n",
    "        self.scaler = MinMaxScaler().fit(X[:, [0]])\n",
    "        self.ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore').fit(X[:, 1:])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.array(X, dtype=object)\n",
    "        ts_scaled = self.scaler.transform(X[:, [0]])\n",
    "        cat_ohe = self.ohe.transform(X[:, 1:])\n",
    "        return sparse.hstack([ts_scaled, cat_ohe]).tocsr()\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "def perm_importance_worker(estimator, X_val, y_val, i, baseline, random_seed):\n",
    "    col = X_val[:, i].copy()\n",
    "    if sparse.issparse(col):\n",
    "        col = col.toarray().ravel()\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    rng.shuffle(col)\n",
    "\n",
    "    X_perm = X_val.copy()\n",
    "    if sparse.issparse(X_perm):\n",
    "        X_perm = X_perm.tolil()\n",
    "        X_perm[:, i] = col.reshape(-1, 1)\n",
    "        X_perm = X_perm.tocsr()\n",
    "    else:\n",
    "        X_perm[:, i] = col\n",
    "\n",
    "    perm_score = roc_auc_score(y_val, estimator.predict_proba(X_perm)[:, 1])\n",
    "    return baseline - perm_score\n",
    "\n",
    "\n",
    "class SparsePermutationImportanceFeatureSelector:\n",
    "    def __init__(self, estimator=None, scoring=roc_auc_score, random_state=42, n_jobs=-1):\n",
    "        self.estimator = estimator if estimator else LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "        self.scoring = scoring\n",
    "        self.random_state = random_state\n",
    "        self.feature_importances_ = None\n",
    "        self.n_jobs = n_jobs  # —á–∏—Å–ª–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not sparse.issparse(X):\n",
    "            X = sparse.csr_matrix(X)\n",
    "\n",
    "        mask = np.arange(X.shape[1])\n",
    "        iteration = 0\n",
    "        best_score = -np.inf\n",
    "        best_mask = mask.copy()\n",
    "        n_splits = 10\n",
    "\n",
    "        while True:\n",
    "            iteration += 1\n",
    "            print(f\"\\n=== –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration} ===\")\n",
    "            X_subset = X[:, mask]\n",
    "            print(f\"–¢–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X_subset.shape[1]}\")\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "            fold_importances_list = []\n",
    "            fold_scores = []\n",
    "\n",
    "            for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X_subset)):\n",
    "                print(f\"\\n--- Fold {fold_idx + 1}/{n_splits} ---\")\n",
    "                X_train, X_val = X_subset[train_idx], X_subset[val_idx]\n",
    "                y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                self.estimator.fit(X_train, y_train)\n",
    "                baseline = self.scoring(y_val, self.estimator.predict_proba(X_val)[:, 1])\n",
    "                fold_scores.append(baseline)\n",
    "                print(f\"ROC-AUC –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {baseline:.4f}\")\n",
    "\n",
    "                # –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ permutation importance –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "                fold_importances = Parallel(n_jobs=self.n_jobs)(\n",
    "                    delayed(perm_importance_worker)(self.estimator, X_val, y_val, i, baseline, self.random_state + fold_idx)\n",
    "                    for i in range(X_subset.shape[1])\n",
    "                )\n",
    "                fold_importances = np.array(fold_importances)\n",
    "                print(f\"–°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ fold {fold_idx + 1}: {np.mean(fold_importances):.6f}\")\n",
    "                fold_importances_list.append(fold_importances)\n",
    "\n",
    "            mean_importances = np.mean(fold_importances_list, axis=0)\n",
    "            avg_score = np.mean(fold_scores)\n",
    "            print(f\"\\n–°—Ä–µ–¥–Ω–∏–π ROC-AUC –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º: {avg_score:.4f}\")\n",
    "            print(f\"–°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤—Å–µ–º —Ñ–æ–ª–¥–∞–º: {np.mean(mean_importances):.6f}\")\n",
    "\n",
    "            if avg_score < best_score:\n",
    "                print(f\"–°—Ä–µ–¥–Ω—è—è –º–µ—Ç—Ä–∏–∫–∞ —É–ø–∞–ª–∞ —Å {best_score:.4f} –¥–æ {avg_score:.4f}. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é.\")\n",
    "                mask = best_mask\n",
    "                break\n",
    "\n",
    "            best_score = avg_score\n",
    "            best_mask = mask.copy()\n",
    "\n",
    "            positive_mask = mean_importances > 0\n",
    "            n_positive = np.sum(positive_mask)\n",
    "            print(f\"–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é: {n_positive} –∏–∑ {len(mean_importances)}\")\n",
    "\n",
    "            if n_positive == X_subset.shape[1]:\n",
    "                print(\"–í—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–º–µ—é—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –≤–∞–∂–Ω–æ—Å—Ç—å. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∫—É—Ä—Å–∏—é.\")\n",
    "                break\n",
    "\n",
    "            mask = mask[positive_mask]\n",
    "            print(f\"–£–¥–∞–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω—É–ª–µ–≤–æ–π –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é, –æ—Å—Ç–∞–≤–ª—è–µ–º {len(mask)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\")\n",
    "\n",
    "        self.feature_importances_ = np.zeros(X.shape[1])\n",
    "        self.feature_importances_[mask] = 1\n",
    "        print(\"\\n–ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—ã—á–∏—Å–ª–µ–Ω–∞!\")\n",
    "        print(f\"–û—Å—Ç–∞–≤–ª–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {np.sum(self.feature_importances_)} –∏–∑ {X.shape[1]}\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        mask = self.feature_importances_ > 0\n",
    "        print(f\"–í—ã–±—Ä–∞–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é: {np.sum(mask)} –∏–∑ {len(mask)}\")\n",
    "        if not sparse.issparse(X):\n",
    "            X = sparse.csr_matrix(X)\n",
    "        return X[:, mask]\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "\n",
    "def postprocess_player_features(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    X: np.ndarray, shape (n_samples, 10)\n",
    "       –ø–µ—Ä–≤—ã–µ 5 —Å—Ç–æ–ª–±—Ü–æ–≤ ‚Äî –∏–≥—Ä–æ–∫–∏ –∫–æ–º–∞–Ω–¥—ã 1\n",
    "       —Å–ª–µ–¥—É—é—â–∏–µ 5 —Å—Ç–æ–ª–±—Ü–æ–≤ ‚Äî –∏–≥—Ä–æ–∫–∏ –∫–æ–º–∞–Ω–¥—ã 2\n",
    "    \"\"\"\n",
    "    X_processed = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        team1 = np.sort(X[i, :5])  # –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã 1\n",
    "        team2 = np.sort(X[i, 5:])  # –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã 2\n",
    "\n",
    "        team1_mean = team1.mean()\n",
    "        team2_mean = team2.mean()\n",
    "        mean_diff = team1_mean - team2_mean\n",
    "\n",
    "        # –ø–æ–ø–∞—Ä–Ω—ã–µ —Ä–∞–∑–Ω–∏—Ü—ã –≤—Å–µ—Ö –∏–≥—Ä–æ–∫–æ–≤ –∫–æ–º–∞–Ω–¥—ã 1 –ø—Ä–æ—Ç–∏–≤ –∫–æ–º–∞–Ω–¥—ã 2\n",
    "        pairwise_diff = []\n",
    "        for j in range(5):\n",
    "            for k in range(5):\n",
    "                pairwise_diff.append(team1[j] - team2[k])\n",
    "\n",
    "        # —Å–æ–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: sorted –∫–æ–º–∞–Ω–¥—ã + —Å—Ä–µ–¥–Ω–∏–µ + —Ä–∞–∑–Ω–∏—Ü–∞ —Å—Ä–µ–¥–Ω–∏—Ö + –ø–æ–ø–∞—Ä–Ω—ã–µ —Ä–∞–∑–Ω–∏—Ü—ã\n",
    "        new_row = np.concatenate([team1, team2, [team1_mean, team2_mean, mean_diff], pairwise_diff])\n",
    "        X_processed.append(new_row)\n",
    "\n",
    "    return np.array(X_processed, dtype=float)\n",
    "  \n",
    "class PlayerStatSumFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Cumulative sum of a player stat across previous games.\"\"\"\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}\n",
    "        self.X_train = None\n",
    "\n",
    "    def _get_player_stat(self, game_id: int) -> dict:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        return {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X_train = np.zeros((X.shape[0], 10), dtype=int)\n",
    "        for i, player_ids in enumerate(X):\n",
    "            # Current cumulative values\n",
    "            self.X_train[i, :] = [self.cumulative_dict.get(p_id, 0) for p_id in player_ids]\n",
    "            # Update cumulative_dict with this game's stats\n",
    "            game_stats = self._get_player_stat(self.game_ids[i])\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + game_stats.get(p_id, 0)        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω X_train (–æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ), –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–µ cumulative\n",
    "        if self.X_train is not None and X.shape[0] == self.X_train.shape[0]:\n",
    "            return postprocess_player_features(self.X_train)\n",
    "        \n",
    "        # –î–ª—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å—á–∏—Ç–∞–µ–º cumulative –Ω–∞ –ª–µ—Ç—É (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å)\n",
    "        X_cumulative_new = np.array([[self.cumulative_dict.get(p_id, 0) for p_id in row] for row in X], dtype=int)\n",
    "        return postprocess_player_features(X_cumulative_new)\n",
    "\n",
    "\n",
    "class PlayerStatMeanFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Mean of a player stat across previous games, —Å post-processing.\"\"\"\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}\n",
    "        self.count_dict = {}\n",
    "        self.X_train = None\n",
    "\n",
    "    def _get_player_stat(self, game_id: int) -> dict:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        return {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X_train = np.zeros((X.shape[0], 10), dtype=float)\n",
    "        for i, player_ids in enumerate(X):\n",
    "            self.X_train[i, :] = [\n",
    "                self.cumulative_dict.get(p_id, 0) / max(self.count_dict.get(p_id, 1), 1)\n",
    "                for p_id in player_ids\n",
    "            ]\n",
    "            game_stats = self._get_player_stat(self.game_ids[i])\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + game_stats.get(p_id, 0)\n",
    "                self.count_dict[p_id] = self.count_dict.get(p_id, 0) + 1        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape[0] == self.X_train.shape[0]:\n",
    "            return postprocess_player_features(self.X_train)\n",
    "        X_mean_new = np.array([\n",
    "            [self.cumulative_dict.get(p_id, 0) / max(self.count_dict.get(p_id, 1), 1) for p_id in row]\n",
    "            for row in X\n",
    "        ], dtype=float)\n",
    "        return postprocess_player_features(X_mean_new)\n",
    "\n",
    "\n",
    "class PlayerStatPerRoundFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Mean stat per round for a player across previous games, —Å post-processing.\"\"\"\n",
    "    def __init__(self, path_to_games_raw_dir: str, game_ids: list[int], key: str = \"kills\"):\n",
    "        self.path_to_games_raw_dir = path_to_games_raw_dir\n",
    "        self.game_ids = game_ids\n",
    "        self.key = key\n",
    "        self.cumulative_dict = {}\n",
    "        self.count_dict = {}\n",
    "        self.X_train = None\n",
    "\n",
    "    def _get_player_stat_per_round(self, game_id: int) -> tuple[dict, int]:\n",
    "        with open(os.path.join(self.path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "            game = json.load(f)\n",
    "        max_round = max(r[\"round\"] for r in game[\"rounds\"])\n",
    "        player_stats = {p[\"player\"][\"id\"]: int(p.get(self.key) or 0) for p in game[\"players\"]}\n",
    "        return player_stats, max_round\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.X_train = np.zeros((X.shape[0], 10), dtype=float)\n",
    "        for i, player_ids in enumerate(X):\n",
    "            game_stats, max_round = self._get_player_stat_per_round(self.game_ids[i])\n",
    "            self.X_train[i, :] = [\n",
    "                self.cumulative_dict.get(p_id, 0) / max(self.count_dict.get(p_id, 1), 1)\n",
    "                for p_id in player_ids\n",
    "            ]\n",
    "            for p_id in player_ids:\n",
    "                self.cumulative_dict[p_id] = self.cumulative_dict.get(p_id, 0) + game_stats.get(p_id, 0)\n",
    "                self.count_dict[p_id] = self.count_dict.get(p_id, 0) + max_round       \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape[0] == self.X_train.shape[0]:\n",
    "            return postprocess_player_features(self.X_train)\n",
    "        X_per_round_new = np.array([\n",
    "            [self.cumulative_dict.get(p_id, 0) / max(self.count_dict.get(p_id, 1), 1) for p_id in row]\n",
    "            for row in X\n",
    "        ], dtype=float)\n",
    "        return postprocess_player_features(X_per_round_new)\n",
    "\n",
    "# --------------------------\n",
    "# FeatureUnion —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –≤—ã—Ö–æ–¥–æ–º\n",
    "# --------------------------\n",
    "class SafeFeatureUnion(FeatureUnion):\n",
    "    def transform(self, X):\n",
    "        Xs = []\n",
    "        for name, trans in self.transformer_list:\n",
    "            X_trans = trans.transform(X)\n",
    "            if not sparse.issparse(X_trans):\n",
    "                X_trans = np.array(X_trans)\n",
    "            Xs.append(X_trans)\n",
    "        if any(sparse.issparse(x) for x in Xs):\n",
    "            Xs = [sparse.csr_matrix(x) if not sparse.issparse(x) else x for x in Xs]\n",
    "            return sparse.hstack(Xs).tocsr()\n",
    "        return np.hstack(Xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c68f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏...\n",
      "\n",
      "üöÄ –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞...\n",
      "\n",
      "=== –ò—Ç–µ—Ä–∞—Ü–∏—è 1 ===\n",
      "–¢–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: 10171\n",
      "\n",
      "--- Fold 1/10 ---\n",
      "ROC-AUC –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: 0.5555\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "N_SPLITS = 10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "PLAYER_STATS_SUM = [\"kills\", \"deaths\", \"assists\", \"headshots\", \"flash_assists\"]\n",
    "PLAYER_STATS_MEAN = [\n",
    "    \"kills\", \"deaths\", \"assists\", \"headshots\", \"flash_assists\",\n",
    "    \"first_kills_diff\", \"k_d_diff\", \"adr\", \"kast\", \"rating\"\n",
    "]\n",
    "\n",
    "TIMESTAMP_COL = [0]\n",
    "GAME_INFO_COL = [1, 2, 3, 4, 5]\n",
    "TEAM_ID_COL = [6, 7]\n",
    "PLAYER_ID_COL = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
    "\n",
    "BASE_ESTIMATOR = LogisticRegression(solver=\"liblinear\", random_state=RANDOM_STATE)\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X_game_info, X_team_id, X_player_id, y = [], [], [], []\n",
    "    for game_id in game_ids:\n",
    "        try:\n",
    "            X_player_id.append(get_player_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_team_id.append(get_team_id_X_for_game(path_to_games_raw, game_id))\n",
    "            X_game_info.append(get_game_info_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except Exception as e:\n",
    "            log.warning(f\"Skipping game {game_id} due to error: {e}\")\n",
    "            continue\n",
    "    return (\n",
    "        np.array(X_game_info, dtype=object),\n",
    "        np.array(X_team_id),\n",
    "        np.array(X_player_id),\n",
    "        np.array(y, dtype=int),\n",
    "    )\n",
    "\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "# ======================================================\n",
    "# –ü–ê–ô–ü–õ–ê–ô–ù\n",
    "# ======================================================\n",
    "pipeline = Pipeline([\n",
    "    ('features', SafeFeatureUnion(\n",
    "        transformer_list=[\n",
    "            # –ò–≥—Ä–æ–∫–∏\n",
    "            ('players', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                ('le', LabelEncoder()),\n",
    "                ('bag', PlayerBagEncoder())\n",
    "            ])),\n",
    "\n",
    "            # –ö–æ–º–∞–Ω–¥—ã\n",
    "            ('teams', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=TEAM_ID_COL)),\n",
    "                ('le', LabelEncoder()),\n",
    "                ('bag', TeamBagEncoder())\n",
    "            ])),\n",
    "\n",
    "            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞—Ç—á–µ\n",
    "            ('game_info', Pipeline([\n",
    "                ('selector', ColumnSelector(columns=TIMESTAMP_COL + GAME_INFO_COL)),\n",
    "                ('encoder', GameInfoEncoder())\n",
    "            ])),\n",
    "\n",
    "            # –°—É–º–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "            *[\n",
    "                (f\"{key}_sum\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_sum\", PlayerStatSumFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in PLAYER_STATS_SUM\n",
    "            ],\n",
    "\n",
    "            # –°—Ä–µ–¥–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "            *[\n",
    "                (f\"{key}_mean\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_mean\", PlayerStatMeanFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in PLAYER_STATS_MEAN\n",
    "            ],\n",
    "\n",
    "            # –°—Ä–µ–¥–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –Ω–∞ —Ä–∞—É–Ω–¥\n",
    "            *[\n",
    "                (f\"{key}_per_round\", Pipeline([\n",
    "                    ('selector', ColumnSelector(columns=PLAYER_ID_COL)),\n",
    "                    (f\"{key}_per_round\", PlayerStatPerRoundFeatureExtractor(\n",
    "                        path_to_games_raw_dir=PATH_TO_GAMES_RAW,\n",
    "                        game_ids=game_ids_train,\n",
    "                        key=key\n",
    "                    )),\n",
    "                    ('scaler', MinMaxScaler())\n",
    "                ]))\n",
    "                for key in PLAYER_STATS_SUM\n",
    "            ]\n",
    "        ]\n",
    "    )),\n",
    "\n",
    "    # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–æ—á–Ω–∞—è –≤–∞–∂–Ω–æ—Å—Ç—å\n",
    "    ('perm_selector', SparsePermutationImportanceFeatureSelector(\n",
    "        estimator=BASE_ESTIMATOR,\n",
    "        scoring=roc_auc_score,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # RFECV\n",
    "    ('rfecv', RFECV(\n",
    "        estimator=BASE_ESTIMATOR,\n",
    "        step=1,\n",
    "        cv=TimeSeriesSplit(n_splits=N_SPLITS),\n",
    "        scoring='roc_auc',\n",
    "        min_features_to_select=1,\n",
    "        verbose=2,\n",
    "        n_jobs=-1\n",
    "    )),\n",
    "\n",
    "    # –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä\n",
    "    ('clf', BASE_ESTIMATOR)\n",
    "])\n",
    "\n",
    "# ======================================================\n",
    "# –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•\n",
    "# ======================================================\n",
    "print(\"\\nüì• –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏...\")\n",
    "X_game_info_train, X_team_id_train, X_player_id_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_game_info_test, X_team_id_test, X_player_id_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "X_train = np.c_[X_game_info_train, X_team_id_train, X_player_id_train]\n",
    "X_test = np.c_[X_game_info_test, X_team_id_test, X_player_id_test]\n",
    "\n",
    "# ======================================================\n",
    "# –û–ë–£–ß–ï–ù–ò–ï\n",
    "# ======================================================\n",
    "print(\"\\nüöÄ –û–±—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ======================================================\n",
    "# –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø\n",
    "# ======================================================\n",
    "print(\"\\nüéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ...\")\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ======================================================\n",
    "# –†–ï–ó–£–õ–¨–¢–ê–¢–´\n",
    "# ======================================================\n",
    "print(\"\\n‚úÖ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ú–û–î–ï–õ–ò:\")\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1-score : {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC-AUC  : {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "print(\"\\n–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67674a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
