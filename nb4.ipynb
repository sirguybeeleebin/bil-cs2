{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# ==============================================================\n",
    "# 1️⃣ Data Loading & Validation\n",
    "# ==============================================================\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for p_ids in team_players.values():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        rounds = [r[\"round\"] for r in game[\"rounds\"] if r[\"round\"] is not None]\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())\n",
    "    X.append(int(game[\"map\"][\"id\"]))              # 0: map_id\n",
    "    X.append(int(game[\"rounds\"][0][\"ct\"]))        # 1: start_ct_team_id\n",
    "    X.extend([t1_id, t2_id])                      # 2-3: team ids\n",
    "    X.extend(sorted(team_players[t1_id]))         # 4-8: team1 player ids\n",
    "    X.extend(sorted(team_players[t2_id]))         # 9-13: team2 player ids\n",
    "    return X\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id: 0, t2_id: 0}\n",
    "    for r in game[\"rounds\"]:\n",
    "        team_win_count[r[\"winner_team\"]] += 1\n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            x_row = get_X_for_game(path_to_games_raw, game_id)\n",
    "            y_row = get_y_for_game(path_to_games_raw, game_id)\n",
    "            X.append(x_row)\n",
    "            y.append(y_row)\n",
    "        except:\n",
    "            continue\n",
    "    X_arr = np.array(X, dtype=int)\n",
    "    y_arr = np.array(y, dtype=int)\n",
    "    assert X_arr.shape[0] == y_arr.shape[0], f\"Mismatched shapes: X={X_arr.shape}, y={y_arr.shape}\"\n",
    "    return X_arr, y_arr\n",
    "\n",
    "# ==============================================================\n",
    "# 2️⃣ Custom Transformers\n",
    "# ==============================================================\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[:, self.columns]\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.encoders = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, col])\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_trans = X.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            X_trans[:, col] = le.transform(X_trans[:, col])\n",
    "        return X_trans.astype(int)\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# ==============================================================\n",
    "# 1️⃣ Data Loading & Validation\n",
    "# ==============================================================\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for p_ids in team_players.values():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        rounds = [r[\"round\"] for r in game[\"rounds\"] if r[\"round\"] is not None]\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())\n",
    "    X.append(int(game[\"map\"][\"id\"]))              # 0: map_id\n",
    "    X.append(int(game[\"rounds\"][0].get(\"ct\", 0))) # 1: start_ct_team_id\n",
    "    X.extend([t1_id, t2_id])                      # 2-3: team ids\n",
    "    X.extend(sorted(team_players[t1_id]))         # 4-8: team1 player ids\n",
    "    X.extend(sorted(team_players[t2_id]))         # 9-13: team2 player ids\n",
    "    return X\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    team_ids = sorted(set(p[\"team\"][\"id\"] for p in game[\"players\"]))\n",
    "    t1_id, t2_id = team_ids\n",
    "    team_win_count = {t1_id: 0, t2_id: 0}\n",
    "    for r in game[\"rounds\"]:\n",
    "        winner = r.get(\"winner_team\")\n",
    "        if winner in team_win_count:\n",
    "            team_win_count[winner] += 1\n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            x_row = get_X_for_game(path_to_games_raw, game_id)\n",
    "            y_row = get_y_for_game(path_to_games_raw, game_id)\n",
    "            X.append(x_row)\n",
    "            y.append(y_row)\n",
    "        except:\n",
    "            continue\n",
    "    X_arr = np.array(X, dtype=int)\n",
    "    y_arr = np.array(y, dtype=int)\n",
    "    assert X_arr.shape[0] == y_arr.shape[0], f\"Mismatched shapes: X={X_arr.shape}, y={y_arr.shape}\"\n",
    "    return X_arr, y_arr\n",
    "\n",
    "# ==============================================================\n",
    "# 2️⃣ Custom Transformers\n",
    "# ==============================================================\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[:, self.columns]\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.encoders = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, col])\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_trans = X.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            X_trans[:, col] = le.transform(X_trans[:, col])\n",
    "        return X_trans.astype(int)\n",
    "\n",
    "class PlayerEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: self.initial_elo)\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            t1, t2 = X[i, :5], X[i, 5:]\n",
    "            res = y[i]\n",
    "            feats.append(self._augment_row(X[i]))\n",
    "            self._update_elos(t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        features = []\n",
    "        for row in X:\n",
    "            features.append(self._augment_row(row))\n",
    "        return np.array(features)\n",
    "\n",
    "    def _augment_row(self, row):\n",
    "        t1, t2 = row[:5], row[5:]\n",
    "        t1e = np.sort([self.player_elos[p] for p in t1])\n",
    "        t2e = np.sort([self.player_elos[p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None, :]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg, t2avg, diff], pairdiff])\n",
    "\n",
    "    def _update_elos(self, t1, t2, res):\n",
    "        t1avg = np.mean([self.player_elos[p] for p in t1])\n",
    "        t2avg = np.mean([self.player_elos[p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg)/400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[p] += delta\n",
    "        for p in t2: self.player_elos[p] -= delta\n",
    "\n",
    "\n",
    "class PlayerMapEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: self.initial_elo))\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            m = X[i,0]\n",
    "            t1, t2 = X[i,1:6], X[i,6:11]\n",
    "            res = y[i]\n",
    "            feats.append(self._augment_row(m, X[i]))\n",
    "            self._update_elos(m, t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        features = []\n",
    "        for row in X:\n",
    "            m = row[0]\n",
    "            features.append(self._augment_row(m, row))\n",
    "        return np.array(features)\n",
    "\n",
    "    def _augment_row(self, m, row):\n",
    "        t1, t2 = row[1:6], row[6:11]\n",
    "        t1e = np.sort([self.player_elos[m][p] for p in t1])\n",
    "        t2e = np.sort([self.player_elos[m][p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None,:]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg,t2avg,diff], pairdiff])\n",
    "\n",
    "    def _update_elos(self, m, t1, t2, res):\n",
    "        t1avg = np.mean([self.player_elos[m][p] for p in t1])\n",
    "        t2avg = np.mean([self.player_elos[m][p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg)/400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[m][p] += delta\n",
    "        for p in t2: self.player_elos[m][p] -= delta\n",
    "\n",
    "\n",
    "class PlayerMapStartEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: self.initial_elo)))\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            m, start_ct = X[i,0], X[i,1]\n",
    "            t1, t2 = X[i,2:7], X[i,7:12]\n",
    "            res = y[i]\n",
    "            feats.append(self._augment_row(m, start_ct, X[i]))\n",
    "            self._update_elos(m, start_ct, t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        features = []\n",
    "        for row in X:\n",
    "            m, start_ct = row[0], row[1]\n",
    "            features.append(self._augment_row(m, start_ct, row))\n",
    "        return np.array(features)\n",
    "\n",
    "    def _augment_row(self, m, start_ct, row):\n",
    "        t1, t2 = row[2:7], row[7:12]\n",
    "        t1e = np.sort([self.player_elos[m][start_ct][p] for p in t1])\n",
    "        t2e = np.sort([self.player_elos[m][start_ct][p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:,None] - t2e[None,:]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg,t2avg,diff], pairdiff])\n",
    "\n",
    "    def _update_elos(self, m, start_ct, t1, t2, res):\n",
    "        t1avg = np.mean([self.player_elos[m][start_ct][p] for p in t1])\n",
    "        t2avg = np.mean([self.player_elos[m][start_ct][p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg)/400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[m][start_ct][p] += delta\n",
    "        for p in t2: self.player_elos[m][start_ct][p] -= delta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645de1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# ==============================================================\n",
    "# 1️⃣ Data Loading & Validation\n",
    "# ==============================================================\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for p_ids in team_players.values():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        rounds = [r[\"round\"] for r in game[\"rounds\"] if r[\"round\"] is not None]\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X_map_id = []\n",
    "    X_start_ct_id = []\n",
    "    X_team_id = []\n",
    "    X_player_id = []\n",
    "    y = []\n",
    "\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            # Load game JSON\n",
    "            with open(os.path.join(path_to_games_raw, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "                game = json.load(f)\n",
    "\n",
    "            # Organize players by team\n",
    "            team_players = defaultdict(list)\n",
    "            for p in game[\"players\"]:\n",
    "                team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "            t1_id, t2_id = sorted(team_players.keys())\n",
    "\n",
    "            # Map ID\n",
    "            X_map_id.append(int(game[\"map\"][\"id\"]))\n",
    "\n",
    "            # Start CT team ID\n",
    "            X_start_ct_id.append(int(game[\"rounds\"][0][\"ct\"]))\n",
    "\n",
    "            # Team IDs\n",
    "            X_team_id.append([t1_id, t2_id])\n",
    "\n",
    "            # Player IDs (10 columns: 5 per team)\n",
    "            player_ids = sorted(team_players[t1_id]) + sorted(team_players[t2_id])\n",
    "            X_player_id.append(player_ids)\n",
    "\n",
    "            # Target (winner)\n",
    "            team_win_count = {t1_id: 0, t2_id: 0}\n",
    "            for r in game[\"rounds\"]:\n",
    "                team_win_count[r[\"winner_team\"]] += 1\n",
    "            y.append(int(team_win_count[t1_id] > team_win_count[t2_id]))\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X_map_id = np.array(X_map_id, dtype=int)\n",
    "    X_start_ct_id = np.array(X_start_ct_id, dtype=int)\n",
    "    X_team_id = np.array(X_team_id, dtype=int)         # shape: (n_games, 2)\n",
    "    X_player_id = np.array(X_player_id, dtype=int)     # shape: (n_games, 10)\n",
    "    y = np.array(y, dtype=int)\n",
    "\n",
    "    return X_map_id, X_start_ct_id, X_team_id, X_player_id, y\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.class_to_index = None\n",
    "\n",
    "    def fit(self, X, y=None):        \n",
    "        uniques = np.unique(X.flatten())\n",
    "        self.class_to_index = dict(zip(uniques, range(len(uniques))))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):        \n",
    "        if self.class_to_index is None:\n",
    "            raise ValueError(\"CustomLabelEncoder has not been fitted yet.\")\n",
    "        vectorized_map = np.vectorize(lambda x: self.class_to_index.get(x, -1))\n",
    "        return vectorized_map(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):        \n",
    "        return self.fit(X, y).transform(X)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc9a95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075a763931224127afb27073c70770cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ebfc7cd064435f9ca77477ee77fd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "X_map_id, X_start_ct_id, X_team_id, X_player_id, y = get_X_y(PATH_TO_GAMES_RAW, game_ids)\n",
    "X_map_id_train = X_map_id[:-TEST_SIZE]\n",
    "\n",
    "\n",
    "X_map_id_train      = X_map_id[:-TEST_SIZE]\n",
    "X_team_id_train      = np.c_[X_start_ct_id[:-TEST_SIZE], X_team_id[:-TEST_SIZE]]\n",
    "X_player_id_train    = X_player_id[:-TEST_SIZE]\n",
    "y_train             = y[:-TEST_SIZE]\n",
    "\n",
    "\n",
    "X_map_id_test       = X_map_id[-TEST_SIZE:]\n",
    "X_team_id_test      = np.c_[X_start_ct_id[-TEST_SIZE:], X_team_id[-TEST_SIZE:]]\n",
    "X_player_id_test     = X_player_id[-TEST_SIZE:]\n",
    "y_test              = y[-TEST_SIZE:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244b428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8, 20, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques = np.unique(X_map_id_train.flatten())\n",
    "d = dict(zip(uniques, range(len(uniques))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdea29d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2672377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ec066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9223ea0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ecdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d7fda33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b39d8cd75944d0be001027759abe94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec18dac2228418c82221ff4ce346ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ce597a1e7b4696abfab63f9043073d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# ==============================================================\n",
    "# 1️⃣ Data Loading & Validation\n",
    "# ==============================================================\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for p_ids in team_players.values():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        rounds = [r[\"round\"] for r in game[\"rounds\"] if r[\"round\"] is not None]\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())\n",
    "    X.append(int(game[\"map\"][\"id\"]))               # 0: map_id\n",
    "    X.append(int(game[\"rounds\"][0].get(\"ct\", 0)))  # 1: start_ct_team_id\n",
    "    X.extend([t1_id, t2_id])                       # 2-3: team ids\n",
    "    X.extend(sorted(team_players[t1_id]))          # 4-8: team1 player ids\n",
    "    X.extend(sorted(team_players[t2_id]))          # 9-13: team2 player ids\n",
    "    return X\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    team_ids = sorted(set(p[\"team\"][\"id\"] for p in game[\"players\"]))\n",
    "    t1_id, t2_id = team_ids\n",
    "    team_win_count = {t1_id: 0, t2_id: 0}\n",
    "    for r in game[\"rounds\"]:\n",
    "        winner = r.get(\"winner_team\")\n",
    "        if winner in team_win_count:\n",
    "            team_win_count[winner] += 1\n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            x_row = get_X_for_game(path_to_games_raw, game_id)\n",
    "            y_row = get_y_for_game(path_to_games_raw, game_id)\n",
    "            X.append(x_row)\n",
    "            y.append(y_row)\n",
    "        except:\n",
    "            continue\n",
    "    X_arr = np.array(X, dtype=int)\n",
    "    y_arr = np.array(y, dtype=int)\n",
    "    assert X_arr.shape[0] == y_arr.shape[0], f\"Mismatched shapes: X={X_arr.shape}, y={y_arr.shape}\"\n",
    "    return X_arr, y_arr\n",
    "\n",
    "# ==============================================================\n",
    "# 2️⃣ Custom Transformers\n",
    "# ==============================================================\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[:, self.columns]\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.encoders = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, col])\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_trans = X.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            X_trans[:, col] = le.transform(X_trans[:, col])\n",
    "        return X_trans.astype(int)\n",
    "\n",
    "# ==============================================================\n",
    "# 3️⃣ Separate ELO Encoders with X_train caching\n",
    "# ==============================================================\n",
    "\n",
    "class PlayerEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: self.initial_elo)\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            t1, t2 = X[i, :5], X[i, 5:]\n",
    "            res = y[i]\n",
    "            feats.append(self._augment_row(X[i]))\n",
    "            self._update_elos(t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        return np.array([self._augment_row(row) for row in X])\n",
    "\n",
    "    def _augment_row(self, row):\n",
    "        t1, t2 = row[:5], row[5:]\n",
    "        t1e = np.sort([self.player_elos[p] for p in t1])\n",
    "        t2e = np.sort([self.player_elos[p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None, :]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg, t2avg, diff], pairdiff])\n",
    "\n",
    "    def _update_elos(self, t1, t2, res):\n",
    "        t1avg = np.mean([self.player_elos[p] for p in t1])\n",
    "        t2avg = np.mean([self.player_elos[p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg)/400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[p] += delta\n",
    "        for p in t2: self.player_elos[p] -= delta\n",
    "\n",
    "class PlayerMapEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: self.initial_elo))\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            m = X[i,0]\n",
    "            t1, t2 = X[i,1:6], X[i,6:11]\n",
    "            res = y[i]\n",
    "            feats.append(self._augment_row(m, X[i]))\n",
    "            self._update_elos(m, t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        return np.array([self._augment_row(row[0], row) for row in X])\n",
    "\n",
    "    def _augment_row(self, m, row):\n",
    "        t1, t2 = row[1:6], row[6:11]\n",
    "        t1e = np.sort([self.player_elos[m][p] for p in t1])\n",
    "        t2e = np.sort([self.player_elos[m][p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None,:]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg,t2avg,diff], pairdiff])\n",
    "\n",
    "    def _update_elos(self, m, t1, t2, res):\n",
    "        t1avg = np.mean([self.player_elos[m][p] for p in t1])\n",
    "        t2avg = np.mean([self.player_elos[m][p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg)/400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[m][p] += delta\n",
    "        for p in t2: self.player_elos[m][p] -= delta\n",
    "\n",
    "class PlayerMapStartEloEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: self.initial_elo)))\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            m, start_ct = X[i,0], X[i,1]\n",
    "            t1, t2 = X[i,2:7], X[i,7:12]\n",
    "            res = y[i]\n",
    "            feats.append(self._augment_row(m, start_ct, X[i]))\n",
    "            self._update_elos(m, start_ct, t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        return np.array([self._augment_row(row[0], row[1], row) for row in X])\n",
    "\n",
    "    def _augment_row(self, m, start_ct, row):\n",
    "        t1, t2 = row[2:7], row[7:12]\n",
    "        t1e = np.sort([self.player_elos[m][start_ct][p] for p in t1])\n",
    "        t2e = np.sort([self.player_elos[m][start_ct][p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:,None] - t2e[None,:]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg,t2avg,diff], pairdiff])\n",
    "\n",
    "    def _update_elos(self, m, start_ct, t1, t2, res):\n",
    "        t1avg = np.mean([self.player_elos[m][start_ct][p] for p in t1])\n",
    "        t2avg = np.mean([self.player_elos[m][start_ct][p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg)/400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[m][start_ct][p] += delta\n",
    "        for p in t2: self.player_elos[m][start_ct][p] -= delta\n",
    "\n",
    "# ==============================================================\n",
    "# 4️⃣ Pipeline Construction\n",
    "# ==============================================================\n",
    "\n",
    "MAP_ID_COL_IDX = [0]\n",
    "START_CT_TEAM_ID_COL_IDX = [1]\n",
    "TEAM_IDS_COL_IDX = [2, 3]\n",
    "PLAYER_IDS_COL_IDX = list(range(4,14))\n",
    "\n",
    "player_elo_pipeline = Pipeline([\n",
    "    ('select_players', ColumnSelector(columns=PLAYER_IDS_COL_IDX)),\n",
    "    ('label_encode_players', MultiColumnLabelEncoder(columns=list(range(len(PLAYER_IDS_COL_IDX))))),\n",
    "    ('player_elo', PlayerEloEncoder())\n",
    "])\n",
    "\n",
    "player_map_elo_pipeline = Pipeline([\n",
    "    ('select_map_players', ColumnSelector(columns=MAP_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('label_encode', MultiColumnLabelEncoder(columns=list(range(len(MAP_ID_COL_IDX + PLAYER_IDS_COL_IDX))))),\n",
    "    ('player_map_elo', PlayerMapEloEncoder())\n",
    "])\n",
    "\n",
    "player_map_start_elo_pipeline = Pipeline([\n",
    "    ('select_map_start_players', ColumnSelector(columns=MAP_ID_COL_IDX + START_CT_TEAM_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('label_encode', MultiColumnLabelEncoder(columns=list(range(len(MAP_ID_COL_IDX + START_CT_TEAM_ID_COL_IDX + PLAYER_IDS_COL_IDX))))),\n",
    "    ('player_map_start_elo', PlayerMapStartEloEncoder())\n",
    "])\n",
    "\n",
    "elo_feature_union = FeatureUnion([\n",
    "    ('player_elo', player_elo_pipeline),\n",
    "    ('player_map_elo', player_map_elo_pipeline),\n",
    "    ('player_map_start_elo', player_map_start_elo_pipeline)\n",
    "])\n",
    "\n",
    "# ==============================================================\n",
    "# 5️⃣ Load data, fit, transform\n",
    "# ==============================================================\n",
    "\n",
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "X_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb414661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,   3284,   3216, ...,  17811,  17833,  17834],\n",
       "       [     3,   3216,   3216, ...,  17811,  17833,  17834],\n",
       "       [     3,   3228,   3210, ...,  17499,  17500,  17543],\n",
       "       ...,\n",
       "       [     2, 126377, 125802, ...,  17501,  17543,  19666],\n",
       "       [     7, 129501, 126709, ...,  21433,  21439,  25439],\n",
       "       [     7, 125751,   5793, ...,  20370,  21440,  23684]],\n",
       "      shape=(38270, 14))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9a7e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0], shape=(38270,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56b5bce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     2,   3310,   3310, ...,  24103,  26620,  26672],\n",
       "       [     7, 129444, 129444, ...,  24243,  29152,  30743],\n",
       "       [     7, 130578,   3310, ...,  24103,  26620,  26672],\n",
       "       ...,\n",
       "       [     8, 130596,   3249, ...,  17799,  18732,  19214],\n",
       "       [    31,   3240,   3240, ...,  40581,  40582,  40583],\n",
       "       [    31, 126738, 126151, ...,  23032,  23035,  23562]],\n",
       "      shape=(100, 14))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbde17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78eb1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ac513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a8b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27909219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee1f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e19b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3ac7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30bd7714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad15a28638464d5aa3dc0d34ebeb1dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8bbfa3b2e50410ba0c852c853dd994f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38270 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b723033de4b48d18a2de319810d19cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "X_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a2520a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,   3284,   3216, ...,  17811,  17833,  17834],\n",
       "       [     3,   3216,   3216, ...,  17811,  17833,  17834],\n",
       "       [     3,   3228,   3210, ...,  17499,  17500,  17543],\n",
       "       ...,\n",
       "       [     2, 126377, 125802, ...,  17501,  17543,  19666],\n",
       "       [     7, 129501, 126709, ...,  21433,  21439,  25439],\n",
       "       [     7, 125751,   5793, ...,  20370,  21440,  23684]],\n",
       "      shape=(38266, 14))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f8de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 0, 1, 0], shape=(38266,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60975eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     2,   3310,   3310, ...,  24103,  26620,  26672],\n",
       "       [     7, 129444, 129444, ...,  24243,  29152,  30743],\n",
       "       [     7, 130578,   3310, ...,  24103,  26620,  26672],\n",
       "       ...,\n",
       "       [     8, 130596,   3249, ...,  17799,  18732,  19214],\n",
       "       [    31,   3240,   3240, ...,  40581,  40582,  40583],\n",
       "       [    31, 126738, 126151, ...,  23032,  23035,  23562]],\n",
       "      shape=(100, 14))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f077140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fc5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8d4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77884f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474587e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71561e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2786b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcd538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990760c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f00be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56493/56493 [00:16<00:00, 3359.73it/s]\n",
      " 68%|██████▊   | 25846/38270 [00:11<00:05, 2234.28it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# =========================================================\n",
    "# Data Utilities\n",
    "# =========================================================\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for p_ids in team_players.values():\n",
    "            assert len(set(p_ids)) == 5\n",
    "        rounds = [r[\"round\"] for r in game[\"rounds\"]]\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())\n",
    "    X = [\n",
    "        int(game[\"map\"][\"id\"]),\n",
    "        int(game[\"rounds\"][0][\"ct\"]),\n",
    "        t1_id,\n",
    "        t2_id\n",
    "    ]\n",
    "    X.extend(sorted(team_players[t1_id]))\n",
    "    X.extend(sorted(team_players[t2_id]))\n",
    "    return X\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id: 0, t2_id: 0}\n",
    "    for r in game[\"rounds\"]:\n",
    "        team_win_count[r[\"winner_team\"]] += 1\n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            X.append(get_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
    "\n",
    "# =========================================================\n",
    "# Transformers\n",
    "# =========================================================\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.columns]\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.encoders = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, col])\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_trans = X.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            X_trans[:, col] = le.transform(X_trans[:, col])\n",
    "        return X_trans.astype(int)\n",
    "\n",
    "# =========================================================\n",
    "# ELO Encoders\n",
    "# =========================================================\n",
    "\n",
    "class PlayerEloEncoder(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: self.initial_elo)\n",
    "        self.X_train = None\n",
    "    def fit(self, X, y):\n",
    "        X_features = []\n",
    "        for i in range(X.shape[0]):\n",
    "            team1_players, team2_players = X[i, :5], X[i, 5:]\n",
    "            result = y[i]\n",
    "            feat_row = self._augment_row(X[i])\n",
    "            X_features.append(feat_row)\n",
    "            self._update_elos(team1_players, team2_players, result)\n",
    "        self.X_train = np.array(X_features)\n",
    "        return self\n",
    "    def transform(self, X):        \n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        features = [self._augment_row(X[i]) for i in range(X.shape[0])]\n",
    "        return np.array(features)\n",
    "    def _augment_row(self, row):        \n",
    "        team1_players, team2_players = row[:5], row[5:]\n",
    "        t1_sorted = np.sort([self.player_elos[p] for p in team1_players])\n",
    "        t2_sorted = np.sort([self.player_elos[p] for p in team2_players])\n",
    "        t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "        t_diff = t1_avg - t2_avg\n",
    "        pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "        return np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "    def _update_elos(self, team1_players, team2_players, result):        \n",
    "        t1_avg = np.mean([self.player_elos[p] for p in team1_players])\n",
    "        t2_avg = np.mean([self.player_elos[p] for p in team2_players])\n",
    "        expected = 1 / (1 + 10 ** ((t2_avg - t1_avg) / 400))\n",
    "        delta = self.k * (result - expected)\n",
    "        for p in team1_players:\n",
    "            self.player_elos[p] += delta\n",
    "        for p in team2_players:\n",
    "            self.player_elos[p] -= delta\n",
    "\n",
    "class PlayerMapEloEncoder(PlayerEloEncoder):    \n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        super().__init__(k, initial_elo)\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: self.initial_elo))\n",
    "    def fit(self, X, y):\n",
    "        X_features = []\n",
    "        for i in range(X.shape[0]):\n",
    "            map_id = X[i, 0]\n",
    "            team1_players, team2_players = X[i, 1:6], X[i, 6:11]\n",
    "            result = y[i]\n",
    "            feat_row = self._augment_row(map_id, X[i])\n",
    "            X_features.append(feat_row)\n",
    "            self._update_elos(map_id, team1_players, team2_players, result)\n",
    "        self.X_train = np.array(X_features)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        features = [self._augment_row(X[i, 0], X[i]) for i in range(X.shape[0])]\n",
    "        return np.array(features)\n",
    "    def _augment_row(self, map_id, row):        \n",
    "        team1_players, team2_players = row[1:6], row[6:11]\n",
    "        t1_sorted = np.sort([self.player_elos[map_id][p] for p in team1_players])\n",
    "        t2_sorted = np.sort([self.player_elos[map_id][p] for p in team2_players])\n",
    "        t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "        t_diff = t1_avg - t2_avg\n",
    "        pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "        return np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "    def _update_elos(self, map_id, team1_players, team2_players, result):        \n",
    "        t1_avg = np.mean([self.player_elos[map_id][p] for p in team1_players])\n",
    "        t2_avg = np.mean([self.player_elos[map_id][p] for p in team2_players])\n",
    "        expected = 1 / (1 + 10 ** ((t2_avg - t1_avg) / 400))\n",
    "        delta = self.k * (result - expected)\n",
    "        for p in team1_players:\n",
    "            self.player_elos[map_id][p] += delta\n",
    "        for p in team2_players:\n",
    "            self.player_elos[map_id][p] -= delta\n",
    "\n",
    "class PlayerMapStartEloEncoder(PlayerMapEloEncoder):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        super().__init__(k, initial_elo)\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: self.initial_elo)))\n",
    "    def fit(self, X, y):\n",
    "        X_features = []\n",
    "        for i in range(X.shape[0]):\n",
    "            map_id, start_ct_id = X[i, 0], X[i, 1]\n",
    "            team1_players, team2_players = X[i, 2:7], X[i, 7:12]\n",
    "            result = y[i]\n",
    "            feat_row = self._augment_row(map_id, start_ct_id, X[i])\n",
    "            X_features.append(feat_row)\n",
    "            self._update_elos(map_id, start_ct_id, team1_players, team2_players, result)\n",
    "        self.X_train = np.array(X_features)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        features = [self._augment_row(X[i, 0], X[i, 1], X[i]) for i in range(X.shape[0])]\n",
    "        return np.array(features)\n",
    "    def _augment_row(self, map_id, start_ct_id, row):        \n",
    "        team1_players, team2_players = row[2:7], row[7:12]\n",
    "        t1_sorted = np.sort([self.player_elos[map_id][start_ct_id][p] for p in team1_players])\n",
    "        t2_sorted = np.sort([self.player_elos[map_id][start_ct_id][p] for p in team2_players])\n",
    "        t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "        t_diff = t1_avg - t2_avg\n",
    "        pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "        return np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "    def _update_elos(self, map_id, start_ct_id, team1_players, team2_players, result):        \n",
    "        t1_avg = np.mean([self.player_elos[map_id][start_ct_id][p] for p in team1_players])\n",
    "        t2_avg = np.mean([self.player_elos[map_id][start_ct_id][p] for p in team2_players])\n",
    "        expected = 1 / (1 + 10 ** ((t2_avg - t1_avg) / 400))\n",
    "        delta = self.k * (result - expected)\n",
    "        for p in team1_players:\n",
    "            self.player_elos[map_id][start_ct_id][p] += delta\n",
    "        for p in team2_players:\n",
    "            self.player_elos[map_id][start_ct_id][p] -= delta\n",
    "\n",
    "# =========================================================\n",
    "# Column Index Config\n",
    "# =========================================================\n",
    "\n",
    "MAP_ID_COL_IDX = [0]\n",
    "START_CT_TEAM_ID_COL_IDX = [1]\n",
    "TEAM_IDS_COL_IDX = [2, 3]\n",
    "PLAYER_IDS_COL_IDX = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "TEAM_ALL_COLS = START_CT_TEAM_ID_COL_IDX + TEAM_IDS_COL_IDX\n",
    "\n",
    "# =========================================================\n",
    "# Pipelines\n",
    "# =========================================================\n",
    "\n",
    "player_elo_pipeline = Pipeline([\n",
    "    ('label_encode_players', MultiColumnLabelEncoder(columns=PLAYER_IDS_COL_IDX)),\n",
    "    ('select_players', ColumnSelector(columns=PLAYER_IDS_COL_IDX)),\n",
    "    ('player_elo', PlayerEloEncoder())\n",
    "])\n",
    "\n",
    "player_map_elo_pipeline = Pipeline([\n",
    "    ('label_encode', MultiColumnLabelEncoder(columns=MAP_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('select_map_players', ColumnSelector(columns=MAP_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('player_map_elo', PlayerMapEloEncoder())\n",
    "])\n",
    "\n",
    "player_map_start_elo_pipeline = Pipeline([\n",
    "    ('label_encode', MultiColumnLabelEncoder(columns=MAP_ID_COL_IDX + TEAM_ALL_COLS + PLAYER_IDS_COL_IDX)),\n",
    "    ('select_map_start_players', ColumnSelector(columns=MAP_ID_COL_IDX + START_CT_TEAM_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('player_map_start_elo', PlayerMapStartEloEncoder())\n",
    "])\n",
    "\n",
    "# =========================================================\n",
    "# Load and Run\n",
    "# =========================================================\n",
    "\n",
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "X_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "player_elo_pipeline.fit(X_train, y_train)\n",
    "player_map_elo_pipeline.fit(X_train, y_train)\n",
    "player_map_start_elo_pipeline.fit(X_train, y_train)\n",
    "\n",
    "X_train_elo = player_elo_pipeline.transform(X_train)\n",
    "X_test_elo = player_elo_pipeline.transform(X_test)\n",
    "\n",
    "X_train_map_elo = player_map_elo_pipeline.transform(X_train)\n",
    "X_test_map_elo = player_map_elo_pipeline.transform(X_test)\n",
    "\n",
    "X_train_map_start_elo = player_map_start_elo_pipeline.transform(X_train)\n",
    "X_test_map_start_elo = player_map_start_elo_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781e7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5138017af18e44dfb92754672a9d23fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad0a6c067f149c997d241ea6e4b3fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2819eb9c2746a1a07d85db9e688ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH_TO_GAMES_RAW = \"data/games_raw\"\n",
    "TEST_SIZE = 100\n",
    "\n",
    "game_ids = get_game_ids(PATH_TO_GAMES_RAW)\n",
    "game_ids_train, game_ids_test = game_ids[:-TEST_SIZE], game_ids[-TEST_SIZE:]\n",
    "\n",
    "X_train, y_train = get_X_y(PATH_TO_GAMES_RAW, game_ids_train)\n",
    "X_test, y_test = get_X_y(PATH_TO_GAMES_RAW, game_ids_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91c8408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,   3284,   3216, ...,  17811,  17833,  17834],\n",
       "       [     3,   3216,   3216, ...,  17811,  17833,  17834],\n",
       "       [     3,   3228,   3210, ...,  17499,  17500,  17543],\n",
       "       ...,\n",
       "       [     8, 125802, 125802, ...,  17501,  17543,  19666],\n",
       "       [     2, 126377, 125802, ...,  17501,  17543,  19666],\n",
       "       [     7, 129501, 126709, ...,  21433,  21439,  25439]],\n",
       "      shape=(37974, 14))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cf4b99c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 38266 is out of bounds for axis 0 with size 38266",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 273\u001b[0m\n\u001b[1;32m    266\u001b[0m elo_feature_union \u001b[38;5;241m=\u001b[39m FeatureUnion([\n\u001b[1;32m    267\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_elo\u001b[39m\u001b[38;5;124m'\u001b[39m, player_elo_pipeline),\n\u001b[1;32m    268\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_map_elo\u001b[39m\u001b[38;5;124m'\u001b[39m, player_map_elo_pipeline),\n\u001b[1;32m    269\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_map_start_elo\u001b[39m\u001b[38;5;124m'\u001b[39m, player_map_start_elo_pipeline)\n\u001b[1;32m    270\u001b[0m ])\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# Fit and transform\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m \u001b[43melo_feature_union\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m X_train_all \u001b[38;5;241m=\u001b[39m elo_feature_union\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[1;32m    275\u001b[0m X_test_all \u001b[38;5;241m=\u001b[39m elo_feature_union\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1909\u001b[0m, in \u001b[0;36mFeatureUnion.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1906\u001b[0m         routed_params[name] \u001b[38;5;241m=\u001b[39m Bunch(fit\u001b[38;5;241m=\u001b[39m{})\n\u001b[1;32m   1907\u001b[0m         routed_params[name]\u001b[38;5;241m.\u001b[39mfit \u001b[38;5;241m=\u001b[39m fit_params\n\u001b[0;32m-> 1909\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_fit_one\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers:\n\u001b[1;32m   1912\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1985\u001b[0m, in \u001b[0;36mFeatureUnion._parallel_func\u001b[0;34m(self, X, y, func, routed_params)\u001b[0m\n\u001b[1;32m   1982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformer_weights()\n\u001b[1;32m   1983\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter())\n\u001b[0;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1989\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatureUnion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1995\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1996\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[1;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     75\u001b[0m     (\n\u001b[1;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     81\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:1556\u001b[0m, in \u001b[0;36m_fit_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;124;03mFits ``transformer`` to ``X`` and ``y``.\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m-> 1556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/pipeline.py:663\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    658\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    659\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    660\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    661\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    662\u001b[0m         )\n\u001b[0;32m--> 663\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 133\u001b[0m, in \u001b[0;36mPlayerEloEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    132\u001b[0m     t1, t2 \u001b[38;5;241m=\u001b[39m X[i, :\u001b[38;5;241m5\u001b[39m], X[i, \u001b[38;5;241m5\u001b[39m:]\n\u001b[0;32m--> 133\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    134\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_augment_row(X[i])\n\u001b[1;32m    135\u001b[0m     feats\u001b[38;5;241m.\u001b[39mappend(f)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 38266 is out of bounds for axis 0 with size 38266"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dateutil.parser import parse\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "# ==============================================================\n",
    "# 1️⃣ Data Loading & Validation\n",
    "# ==============================================================\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for p_ids in team_players.values():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        team_ids = list(team_players.keys())\n",
    "        rounds = [r[\"round\"] for r in game[\"rounds\"] if r[\"round\"] is not None]\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid, game_begin_at_valid = [], []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())\n",
    "    X.append(int(game[\"map\"][\"id\"]))              # 0: map_id\n",
    "    X.append(int(game[\"rounds\"][0][\"ct\"]))        # 1: start_ct_team_id\n",
    "    X.extend([t1_id, t2_id])                      # 2-3: team ids\n",
    "    X.extend(sorted(team_players[t1_id]))         # 4-8: team1 player ids\n",
    "    X.extend(sorted(team_players[t2_id]))         # 9-13: team2 player ids\n",
    "    return X\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id: 0, t2_id: 0}\n",
    "    for r in game[\"rounds\"]:\n",
    "        team_win_count[r[\"winner_team\"]] += 1\n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            X.append(get_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
    "\n",
    "# ==============================================================\n",
    "# 2️⃣ Custom Transformers\n",
    "# ==============================================================\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return X[:, self.columns]\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.encoders = {}\n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.columns:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[:, col])\n",
    "            self.encoders[col] = le\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_trans = X.copy()\n",
    "        for col, le in self.encoders.items():\n",
    "            X_trans[:, col] = le.transform(X_trans[:, col])\n",
    "        return X_trans.astype(int)\n",
    "\n",
    "# ==============================================================\n",
    "# 3️⃣ ELO Encoders\n",
    "# ==============================================================\n",
    "\n",
    "class PlayerEloEncoder(BaseEstimator, TransformerMixin):    \n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        self.k, self.initial_elo = k, initial_elo\n",
    "        self.player_elos = defaultdict(lambda: self.initial_elo)\n",
    "        self.X_train = None\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            t1, t2 = X[i, :5], X[i, 5:]\n",
    "            res = y[i]\n",
    "            f = self._augment_row(X[i])\n",
    "            feats.append(f)\n",
    "            self._update_elos(t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        return np.array([self._augment_row(row) for row in X])\n",
    "    def _augment_row(self, row):\n",
    "        t1, t2 = row[:5], row[5:]\n",
    "        t1e, t2e = np.sort([self.player_elos[p] for p in t1]), np.sort([self.player_elos[p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None, :]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg, t2avg, diff], pairdiff])\n",
    "    def _update_elos(self, t1, t2, res):\n",
    "        t1avg, t2avg = np.mean([self.player_elos[p] for p in t1]), np.mean([self.player_elos[p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg) / 400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[p] += delta\n",
    "        for p in t2: self.player_elos[p] -= delta\n",
    "\n",
    "class PlayerMapEloEncoder(PlayerEloEncoder):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        super().__init__(k, initial_elo)\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: self.initial_elo))\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            m = X[i, 0]\n",
    "            t1, t2 = X[i, 1:6], X[i, 6:11]\n",
    "            res = y[i]\n",
    "            f = self._augment_row(m, X[i])\n",
    "            feats.append(f)\n",
    "            self._update_elos(m, t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        return np.array([self._augment_row(row[0], row) for row in X])\n",
    "    def _augment_row(self, m, row):\n",
    "        t1, t2 = row[1:6], row[6:11]\n",
    "        t1e, t2e = np.sort([self.player_elos[m][p] for p in t1]), np.sort([self.player_elos[m][p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None, :]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg, t2avg, diff], pairdiff])\n",
    "    def _update_elos(self, m, t1, t2, res):\n",
    "        t1avg, t2avg = np.mean([self.player_elos[m][p] for p in t1]), np.mean([self.player_elos[m][p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg) / 400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[m][p] += delta\n",
    "        for p in t2: self.player_elos[m][p] -= delta\n",
    "\n",
    "class PlayerMapStartEloEncoder(PlayerEloEncoder):\n",
    "    def __init__(self, k=30, initial_elo=1500):\n",
    "        super().__init__(k, initial_elo)\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: self.initial_elo)))\n",
    "    def fit(self, X, y):\n",
    "        feats = []\n",
    "        for i in range(X.shape[0]):\n",
    "            m, start_ct = X[i, 0], X[i, 1]\n",
    "            t1, t2 = X[i, 2:7], X[i, 7:12]\n",
    "            res = y[i]\n",
    "            f = self._augment_row(m, start_ct, X[i])\n",
    "            feats.append(f)\n",
    "            self._update_elos(m, start_ct, t1, t2, res)\n",
    "        self.X_train = np.array(feats)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if self.X_train is not None and X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        return np.array([self._augment_row(row[0], row[1], row) for row in X])\n",
    "    def _augment_row(self, m, start_ct, row):\n",
    "        t1, t2 = row[2:7], row[7:12]\n",
    "        t1e, t2e = np.sort([self.player_elos[m][start_ct][p] for p in t1]), np.sort([self.player_elos[m][start_ct][p] for p in t2])\n",
    "        t1avg, t2avg = np.mean(t1e), np.mean(t2e)\n",
    "        diff = t1avg - t2avg\n",
    "        pairdiff = (t1e[:, None] - t2e[None, :]).flatten()\n",
    "        return np.concatenate([t1e, t2e, [t1avg, t2avg, diff], pairdiff])\n",
    "    def _update_elos(self, m, start_ct, t1, t2, res):\n",
    "        t1avg, t2avg = np.mean([self.player_elos[m][start_ct][p] for p in t1]), np.mean([self.player_elos[m][start_ct][p] for p in t2])\n",
    "        exp = 1 / (1 + 10 ** ((t2avg - t1avg) / 400))\n",
    "        delta = self.k * (res - exp)\n",
    "        for p in t1: self.player_elos[m][start_ct][p] += delta\n",
    "        for p in t2: self.player_elos[m][start_ct][p] -= delta\n",
    "\n",
    "# ==============================================================\n",
    "# 4️⃣ Pipeline Construction\n",
    "# ==============================================================\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# Column indices\n",
    "MAP_ID_COL_IDX = [0]\n",
    "START_CT_TEAM_ID_COL_IDX = [1]\n",
    "TEAM_IDS_COL_IDX = [2, 3]\n",
    "PLAYER_IDS_COL_IDX = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "TEAM_ALL_COLS = START_CT_TEAM_ID_COL_IDX + TEAM_IDS_COL_IDX\n",
    "\n",
    "# -------------------------------\n",
    "# Player Elo pipeline\n",
    "# -------------------------------\n",
    "player_elo_pipeline = Pipeline([\n",
    "    ('select_players', ColumnSelector(columns=PLAYER_IDS_COL_IDX)),\n",
    "    ('label_encode_players', MultiColumnLabelEncoder(columns=list(range(len(PLAYER_IDS_COL_IDX))))),\n",
    "    ('player_elo', PlayerEloEncoder())\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Player + Map Elo pipeline\n",
    "# -------------------------------\n",
    "player_map_elo_pipeline = Pipeline([\n",
    "    ('select_map_players', ColumnSelector(columns=MAP_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('label_encode', MultiColumnLabelEncoder(columns=list(range(len(MAP_ID_COL_IDX + PLAYER_IDS_COL_IDX))))),\n",
    "    ('player_map_elo', PlayerMapEloEncoder())\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Player + Map + Start Team Elo pipeline\n",
    "# -------------------------------\n",
    "player_map_start_elo_pipeline = Pipeline([\n",
    "    ('select_map_start_players', ColumnSelector(columns=MAP_ID_COL_IDX + START_CT_TEAM_ID_COL_IDX + PLAYER_IDS_COL_IDX)),\n",
    "    ('label_encode', MultiColumnLabelEncoder(columns=list(range(len(MAP_ID_COL_IDX + START_CT_TEAM_ID_COL_IDX + PLAYER_IDS_COL_IDX))))),\n",
    "    ('player_map_start_elo', PlayerMapStartEloEncoder())\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# Combine all pipelines\n",
    "# -------------------------------\n",
    "elo_feature_union = FeatureUnion([\n",
    "    ('player_elo', player_elo_pipeline),\n",
    "    ('player_map_elo', player_map_elo_pipeline),\n",
    "    ('player_map_start_elo', player_map_start_elo_pipeline)\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "elo_feature_union.fit(X_train, y_train)\n",
    "X_train_all = elo_feature_union.transform(X_train)\n",
    "X_test_all = elo_feature_union.transform(X_test)\n",
    "\n",
    "print(\"Final Combined Feature Shapes:\")\n",
    "print(\"Train:\", X_train_all.shape)\n",
    "print(\"Test:\", X_test_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41d76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34898d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49dc0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f59300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e01370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79d904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e207bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e6c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69024334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f0e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Map map_id to integer indices ---\n",
    "uniques = np.unique(X_train[:, 0])\n",
    "map_dict = dict(zip(uniques, range(len(uniques))))\n",
    "for i in range(X_train.shape[0]):\n",
    "    X_train[i, 0] = map_dict.get(X_train[i, 0], -1)\n",
    "for i in range(X_test.shape[0]):\n",
    "    X_test[i, 0] = map_dict.get(X_test[i, 0], -1)\n",
    "\n",
    "# --- Map team IDs (start_ct, t1_id, t2_id) to integer indices ---\n",
    "uniques = np.unique(X_train[:, [1, 2, 3]].flatten())\n",
    "team_dict = dict(zip(uniques, range(len(uniques))))\n",
    "for i in range(X_train.shape[0]):\n",
    "    for j in [1, 2, 3]:\n",
    "        X_train[i, j] = team_dict.get(X_train[i, j], -1)\n",
    "for i in range(X_test.shape[0]):\n",
    "    for j in [1, 2, 3]:\n",
    "        X_test[i, j] = team_dict.get(X_test[i, j], -1)\n",
    "\n",
    "# --- Map player IDs (columns 4-13) to integer indices ---\n",
    "uniques = np.unique(X_train[:, 4:14].flatten())\n",
    "player_dict = dict(zip(uniques, range(len(uniques))))\n",
    "for i in range(X_train.shape[0]):\n",
    "    for j in range(4, 14):\n",
    "        X_train[i, j] = player_dict.get(X_train[i, j], -1)\n",
    "for i in range(X_test.shape[0]):\n",
    "    for j in range(4, 14):\n",
    "        X_test[i, j] = player_dict.get(X_test[i, j], -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a17ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlayerEloExtractor: (37974, 38) (100, 38)\n",
      "PlayerMapEloExtractor: (37974, 38) (100, 38)\n",
      "PlayerMapStartEloExtractor: (37974, 38) (100, 38)\n",
      "Logistic Regression performance on test set:\n",
      "Auc: 0.5000\n",
      "Accuracy: 0.5700\n",
      "Precision: 0.5700\n",
      "Recall: 1.0000\n",
      "F1: 0.7261\n",
      "Confusion matrix: TP=57, TN=0, FP=43, FN=0\n"
     ]
    }
   ],
   "source": [
    "# 1️⃣ General player Elo\n",
    "player_elo_extractor = PlayerEloExtractor(k=30, initial_elo=1500)\n",
    "player_elo_extractor.fit(X_train, y_train)\n",
    "X_train_elo = player_elo_extractor.transform(X_train)\n",
    "X_test_elo = player_elo_extractor.transform(X_test)\n",
    "print(\"PlayerEloExtractor:\", X_train_elo.shape, X_test_elo.shape)\n",
    "\n",
    "# 2️⃣ Player Elo per map\n",
    "player_map_elo_extractor = PlayerMapEloExtractor(k=30, initial_elo=1500)\n",
    "player_map_elo_extractor.fit(X_train, y_train)\n",
    "X_train_map_elo = player_map_elo_extractor.transform(X_train)\n",
    "X_test_map_elo = player_map_elo_extractor.transform(X_test)\n",
    "print(\"PlayerMapEloExtractor:\", X_train_map_elo.shape, X_test_map_elo.shape)\n",
    "\n",
    "# 3️⃣ Player Elo per map & starting CT side\n",
    "player_map_start_elo_extractor = PlayerMapStartEloExtractor(initial_elo=1500)\n",
    "player_map_start_elo_extractor.fit(X_train, y_train)\n",
    "X_train_map_start_elo = player_map_start_elo_extractor.transform(X_train)\n",
    "X_test_map_start_elo = player_map_start_elo_extractor.transform(X_test)\n",
    "print(\"PlayerMapStartEloExtractor:\", X_train_map_start_elo.shape, X_test_map_start_elo.shape)\n",
    "\n",
    "# ------------------------------\n",
    "# Train Logistic Regression (example with PlayerMapStartElo features)\n",
    "# ------------------------------\n",
    "clf, metrics = train_and_evaluate_logit(\n",
    "    X_train_map_start_elo, y_train,\n",
    "    X_test_map_start_elo, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783647e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a91d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336fb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af004eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9e9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f7a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b284d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88406cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fe9d68145b4108a6d5a4917c1c230e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66fb4bd3e024d4cbed33fe0f3d8f1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37974 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b948680063347c28c40e32e4e552f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Map unique player IDs to integer indices (columns 4-13)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m player_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m unique_players \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_columns\u001b[49m\u001b[43m]\u001b[49m, X_test[:, player_columns]]))\n\u001b[1;32m     17\u001b[0m player_dict \u001b[38;5;241m=\u001b[39m {pid: idx \u001b[38;5;28;01mfor\u001b[39;00m idx, pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(unique_players)}\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m [X_train, X_test]:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "player_columns = list(range(4, 14))\n",
    "unique_players = np.unique(np.concatenate([X_train[:, player_columns], X_test[:, player_columns]]))\n",
    "player_dict = {pid: idx for idx, pid in enumerate(unique_players)}\n",
    "\n",
    "for arr in [X_train, X_test]:\n",
    "    for i in range(arr.shape[0]):\n",
    "        for j in player_columns:\n",
    "            arr[i, j] = player_dict.get(arr[i, j], -1)\n",
    "\n",
    "# Compute Elo features\n",
    "elo_extractor = PlayerEloExtractor(k=30, initial_elo=1500)\n",
    "elo_extractor.fit(X_train, y_train)\n",
    "X_train_elo = elo_extractor.transform(X_train)\n",
    "X_test_elo = elo_extractor.transform(X_test)\n",
    "\n",
    "print(\"Training Elo features shape:\", X_train_elo.shape)\n",
    "print(\"Test Elo features shape:\", X_test_elo.shape)\n",
    "\n",
    "# Train and evaluate Logistic Regression\n",
    "clf, metrics = train_and_evaluate_logit(X_train_elo, y_train, X_test_elo, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09aa9c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17525, 17539, 17540, ..., 17811, 17833, 17834],\n",
       "       [17525, 17539, 17540, ..., 17811, 17833, 17834],\n",
       "       [17520, 17523, 17555, ..., 17499, 17500, 17543],\n",
       "       ...,\n",
       "       [20678, 20684, 20692, ..., 17501, 17543, 19666],\n",
       "       [20678, 20684, 20692, ..., 17501, 17543, 19666],\n",
       "       [20569, 25589, 27555, ..., 21433, 21439, 25439]], shape=(37974, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782b741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c637bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05cd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da87ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ef7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Data Loading & Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def generate_game_raw(path_to_games_raw_dir: str = \"data/games_raw\"):\n",
    "    for filename in tqdm(os.listdir(path_to_games_raw_dir)):\n",
    "        try:\n",
    "            with open(os.path.join(path_to_games_raw_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "                yield json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def validate_game(game: dict) -> bool:\n",
    "    try:\n",
    "        int(game[\"id\"])\n",
    "        parse(game[\"begin_at\"])\n",
    "        int(game[\"match\"][\"league\"][\"id\"])\n",
    "        int(game[\"match\"][\"serie\"][\"id\"])\n",
    "        int(game[\"match\"][\"tournament\"][\"id\"])\n",
    "        int(game[\"map\"][\"id\"])\n",
    "\n",
    "        team_players = defaultdict(list)\n",
    "        for p in game[\"players\"]:\n",
    "            team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "        assert len(team_players) == 2\n",
    "        for t_id, p_ids in team_players.items():\n",
    "            assert len(set(p_ids)) == 5\n",
    "\n",
    "        team_ids = list(team_players.keys())\n",
    "        rounds = []\n",
    "        for r in game[\"rounds\"]:\n",
    "            assert r[\"round\"] is not None\n",
    "            assert r[\"ct\"] in team_ids\n",
    "            assert r[\"terrorists\"] in team_ids\n",
    "            assert r[\"winner_team\"] in team_ids\n",
    "            rounds.append(r[\"round\"])\n",
    "        assert min(rounds) == 1\n",
    "        assert max(rounds) >= 16\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_game_ids(path_to_games_raw_dir: str = \"data/games_raw\") -> list[int]:\n",
    "    game_ids_valid = []\n",
    "    game_begin_at_valid = []\n",
    "    for game in generate_game_raw(path_to_games_raw_dir):\n",
    "        if validate_game(game):\n",
    "            game_ids_valid.append(game[\"id\"])\n",
    "            game_begin_at_valid.append(parse(game[\"begin_at\"]))\n",
    "    return np.array(game_ids_valid)[np.argsort(game_begin_at_valid)].tolist()\n",
    "\n",
    "def get_X_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    X = []\n",
    "    team_players = defaultdict(list)\n",
    "    for p in game[\"players\"]:\n",
    "        team_players[p[\"team\"][\"id\"]].append(p[\"player\"][\"id\"])\n",
    "    t1_id, t2_id = sorted(team_players.keys())\n",
    "    X.append(int(game[\"map\"][\"id\"]))\n",
    "    X.append(int(game[\"rounds\"][0][\"ct\"]))\n",
    "    X.extend([t1_id, t2_id])\n",
    "    X.extend(sorted(team_players[t1_id]))\n",
    "    X.extend(sorted(team_players[t2_id]))\n",
    "    return X\n",
    "\n",
    "def get_y_for_game(path_to_games_raw_dir: str, game_id: int):\n",
    "    with open(os.path.join(path_to_games_raw_dir, f\"{game_id}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        game = json.load(f)\n",
    "    t1_id, t2_id = np.unique([p[\"team\"][\"id\"] for p in game[\"players\"]])\n",
    "    team_win_count = {t1_id:0, t2_id:0}\n",
    "    for r in game[\"rounds\"]:\n",
    "        team_win_count[r[\"winner_team\"]] += 1\n",
    "    return int(team_win_count[t1_id] > team_win_count[t2_id])\n",
    "\n",
    "def get_X_y(path_to_games_raw: str, game_ids: list[int]):\n",
    "    X, y = [], []\n",
    "    for game_id in tqdm(game_ids):\n",
    "        try:\n",
    "            X.append(get_X_for_game(path_to_games_raw, game_id))\n",
    "            y.append(get_y_for_game(path_to_games_raw, game_id))\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(X, dtype=int), np.array(y, dtype=int)\n",
    "\n",
    "# ------------------------------\n",
    "# Player Elo Extractor\n",
    "# ------------------------------\n",
    "\n",
    "class PlayerEloExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Elo features per match:\n",
    "    - Sorted team1 Elo (5)\n",
    "    - Sorted team2 Elo (5)\n",
    "    - Team averages (2)\n",
    "    - Team Elo difference (1)\n",
    "    - Pairwise differences (25)\n",
    "    Total: 38 features\n",
    "    \"\"\"\n",
    "    def __init__(self, k: int = 30, initial_elo: int = 1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        self.player_elos = defaultdict(lambda: self.initial_elo)\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X_train = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            team1_players, team2_players = X[i, :5], X[i, 5:10]\n",
    "            result = y[i]\n",
    "\n",
    "            # Sorted Elo\n",
    "            t1_sorted = np.sort([self.player_elos[p] for p in team1_players])\n",
    "            t2_sorted = np.sort([self.player_elos[p] for p in team2_players])\n",
    "\n",
    "            # Team averages & diff\n",
    "            t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "            t_diff = t1_avg - t2_avg\n",
    "\n",
    "            # Pairwise differences\n",
    "            pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "\n",
    "            # Concatenate features\n",
    "            feat_row = np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "            X_train.append(feat_row)\n",
    "\n",
    "            # Update Elo after game\n",
    "            self._update_elos(team1_players, team2_players, result)\n",
    "\n",
    "        self.X_train = np.array(X_train)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray):\n",
    "        if X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        \n",
    "        features = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            team1_players, team2_players = X[i, :5], X[i, 5:10]\n",
    "\n",
    "            t1_sorted = np.sort([self.player_elos[p] for p in team1_players])\n",
    "            t2_sorted = np.sort([self.player_elos[p] for p in team2_players])\n",
    "\n",
    "            t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "            t_diff = t1_avg - t2_avg\n",
    "\n",
    "            pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "\n",
    "            feat_row = np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "            features.append(feat_row)\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "    def _update_elos(self, team1_players, team2_players, result):\n",
    "        t1_avg = np.mean([self.player_elos[p] for p in team1_players])\n",
    "        t2_avg = np.mean([self.player_elos[p] for p in team2_players])\n",
    "        expected = 1 / (1 + 10 ** ((t2_avg - t1_avg) / 400))\n",
    "        delta1 = self.k * (result - expected)\n",
    "        delta2 = self.k * ((1 - result) - (1 - expected))\n",
    "\n",
    "        for p in team1_players:\n",
    "            self.player_elos[p] += delta1\n",
    "        for p in team2_players:\n",
    "            self.player_elos[p] += delta2\n",
    "            \n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PlayerMapEloExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Elo features per match with per-map Elo:\n",
    "    - Sorted team1 Elo (5)\n",
    "    - Sorted team2 Elo (5)\n",
    "    - Team averages (2)\n",
    "    - Team Elo difference (1)\n",
    "    - Pairwise differences (25)\n",
    "    Total: 38 features\n",
    "    \"\"\"\n",
    "    def __init__(self, k: int = 30, initial_elo: int = 1500):\n",
    "        self.k = k\n",
    "        self.initial_elo = initial_elo\n",
    "        # player_elos[map_id][player_id] = elo\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: self.initial_elo))\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        X_train = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            map_id = X[i, 0]  # assume first column is map_id\n",
    "            team1_players, team2_players = X[i, 1:6], X[i, 6:11]\n",
    "            result = y[i]\n",
    "\n",
    "            # Sorted Elo (per map)\n",
    "            t1_sorted = np.sort([self.player_elos[map_id][p] for p in team1_players])\n",
    "            t2_sorted = np.sort([self.player_elos[map_id][p] for p in team2_players])\n",
    "\n",
    "            # Team averages & difference\n",
    "            t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "            t_diff = t1_avg - t2_avg\n",
    "\n",
    "            # Pairwise differences\n",
    "            pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "\n",
    "            # Combine features\n",
    "            feat_row = np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "            X_train.append(feat_row)\n",
    "\n",
    "            # Update Elo per map\n",
    "            self._update_elos(map_id, team1_players, team2_players, result)\n",
    "\n",
    "        self.X_train = np.array(X_train)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray):\n",
    "        if X.shape == self.X_train.shape:\n",
    "            return self.X_train\n",
    "        \n",
    "        features = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            map_id = X[i, 0]\n",
    "            team1_players, team2_players = X[i, 1:6], X[i, 6:11]\n",
    "\n",
    "            t1_sorted = np.sort([self.player_elos[map_id][p] for p in team1_players])\n",
    "            t2_sorted = np.sort([self.player_elos[map_id][p] for p in team2_players])\n",
    "\n",
    "            t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "            t_diff = t1_avg - t2_avg\n",
    "\n",
    "            pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "\n",
    "            feat_row = np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "            features.append(feat_row)\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "    def _update_elos(self, map_id, team1_players, team2_players, result):\n",
    "        t1_avg = np.mean([self.player_elos[map_id][p] for p in team1_players])\n",
    "        t2_avg = np.mean([self.player_elos[map_id][p] for p in team2_players])\n",
    "        expected = 1 / (1 + 10 ** ((t2_avg - t1_avg) / 400))\n",
    "        delta1 = self.k * (result - expected)\n",
    "        delta2 = self.k * ((1 - result) - (1 - expected))\n",
    "\n",
    "        for p in team1_players:\n",
    "            self.player_elos[map_id][p] += delta1\n",
    "        for p in team2_players:\n",
    "            self.player_elos[map_id][p] += delta2\n",
    "            \n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class PlayerMapStartEloExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Elo features per match using per-map and starting CT-side Elo (no updates)\n",
    "    Features per match:\n",
    "    - Sorted team1 Elo (5)\n",
    "    - Sorted team2 Elo (5)\n",
    "    - Team averages (2)\n",
    "    - Team Elo difference (1)\n",
    "    - Pairwise differences (25)\n",
    "    Total: 38 features\n",
    "    Column mapping based on get_X_for_game:\n",
    "    0: map_id\n",
    "    1: start_ct_team_id\n",
    "    2-3: t1_id, t2_id\n",
    "    4-8: team1 player ids\n",
    "    9-13: team2 player ids\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_elo: int = 1500):\n",
    "        self.initial_elo = initial_elo\n",
    "        # Elo stored per map and per starting CT side\n",
    "        self.player_elos = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: self.initial_elo)))\n",
    "        self.X_train = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray = None):\n",
    "        X_train = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            map_id = X[i, 0]\n",
    "            start_ct_id = X[i, 1]\n",
    "            team1_players, team2_players = X[i, 4:9], X[i, 9:14]\n",
    "\n",
    "            # Sorted starting Elo using map_id and start_ct_id\n",
    "            t1_sorted = np.sort([self.player_elos[map_id][start_ct_id][p] for p in team1_players])\n",
    "            t2_sorted = np.sort([self.player_elos[map_id][start_ct_id][p] for p in team2_players])\n",
    "\n",
    "            t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "            t_diff = t1_avg - t2_avg\n",
    "            pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "\n",
    "            feat_row = np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "            X_train.append(feat_row)\n",
    "\n",
    "        self.X_train = np.array(X_train)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray):\n",
    "        features = []\n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            map_id = X[i, 0]\n",
    "            start_ct_id = X[i, 1]\n",
    "            team1_players, team2_players = X[i, 4:9], X[i, 9:14]\n",
    "\n",
    "            t1_sorted = np.sort([self.player_elos[map_id][start_ct_id][p] for p in team1_players])\n",
    "            t2_sorted = np.sort([self.player_elos[map_id][start_ct_id][p] for p in team2_players])\n",
    "\n",
    "            t1_avg, t2_avg = np.mean(t1_sorted), np.mean(t2_sorted)\n",
    "            t_diff = t1_avg - t2_avg\n",
    "            pairwise_diff = (t1_sorted[:, None] - t2_sorted[None, :]).flatten()\n",
    "\n",
    "            feat_row = np.concatenate([t1_sorted, t2_sorted, [t1_avg, t2_avg, t_diff], pairwise_diff])\n",
    "            features.append(feat_row)\n",
    "\n",
    "        return np.array(features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "def train_and_evaluate_logit(X_train, y_train, X_test, y_test, random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Train Logistic Regression on training data and evaluate on test data.\n",
    "    \n",
    "    Returns:\n",
    "        clf: trained LogisticRegression model\n",
    "        metrics: dict of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Train\n",
    "    clf = LogisticRegression(solver=\"liblinear\", random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute metrics\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    metrics = {\n",
    "        \"auc\": roc_auc_score(y_test, y_proba),\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"confusion_matrix\": {\"TP\": tp, \"TN\": tn, \"FP\": fp, \"FN\": fn},\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"Logistic Regression performance on test set:\")\n",
    "    for k, v in metrics.items():\n",
    "        if k != \"confusion_matrix\":\n",
    "            print(f\"{k.capitalize()}: {v:.4f}\")\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "    print(f\"Confusion matrix: TP={cm['TP']}, TN={cm['TN']}, FP={cm['FP']}, FN={cm['FN']}\")\n",
    "\n",
    "    return clf, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d4044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7ba5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression performance on test set:\n",
      "Auc: 0.7472\n",
      "Accuracy: 0.6600\n",
      "Precision: 0.6667\n",
      "Recall: 0.8070\n",
      "F1: 0.7302\n",
      "Confusion matrix: TP=46, TN=20, FP=23, FN=11\n"
     ]
    }
   ],
   "source": [
    "clf, metrics = train_and_evaluate_logit(X_train_elo, y_train, X_test_elo, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb70bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61288013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a648579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167af7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a8782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c922541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
